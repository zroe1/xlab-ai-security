# Adversarial Training #

Adversarial Training is a method of increasing the "adversarial robustness", the resistance to intentionally confusing input, of a particular model. It generally involves adding adversarially perturbed samples to the training dataset of the model. This allows it to gain resistance to adversarial patterns, reducing misclassification. 

For the purposes of the notebook, we will be using the MNIST dataset. This classic dataset is a collection of handwritten numbers (from 0-9), stored as black and white image files. We will use the PGD algorithm from a previous section to generate adversarial images to use in the new, robust dataset. 
