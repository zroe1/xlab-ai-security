---
title: "Square Attack"
description: "Background information on the square attack."
---

This section has a series of coding problems using PyTorch. _As always, we highly recommend you read
all the content on this page before starting the coding exercises._

<ExerciseButtons
  githubUrl="https://github.com/zroe1/xlab-ai-security/blob/main/working/adversarial_basics/square/square.ipynb"
  colabUrl="https://colab.research.google.com/github/zroe1/xlab-ai-security/blob/main/working/adversarial_basics/square/square.ipynb"
/>

## Introduction

The Square Attack [@andriushchenko2020squareattackqueryefficientblackbox] is a black-box method used to generate adversarial samples. Unlike 'white-box' approaches such as PGD or FGSM, the Square Attack does not require knowing model weights or gradients.

While other black-box attacks take many queries to perform attacks, the square attack requires relatively few. The attack works by taking repeated alterations in the shape of a square on the image, keeping it if it increases the loss of the model. The Square Attack, upon release, was successful enough that it even outperformed some existing white-box approaches on benchmarks.

While both $L_\infty$ and $L_2$ variations of the attack exist, we focus on the $L_\infty$ attack. We believe that the $L_\infty$ attack is sufficient to learn the main concepts behind the attack. At the bottom of this writeup we include limited information about the $L_2$ attack as well but we warn readers that this content is quite technical and not necessary to understand for future sections of the course.

<p align="center">
  <img
    src="/images/square_attack.png"
    alt="A descriptive alt text"
    style={{ maxWidth: "100%", height: "auto" }}
  />
  <br />
  <b>Fig. 1</b>
  <br />
  <em>Source: [@andriushchenko2020squareattackqueryefficientblackbox]</em>
</p>

## The Square Attack Loop

The Square Attack works through a random sampling algorithm. First, the adversarial image $\hat{x}$ is initialized as the input image, and the loss is initialized as the loss function of $model(x)$ and $y$. For each iteration, a square of pixels is randomly chosen and perturbed. If the addition of this square to $\hat{x}$ increases loss, this addition is kept. If not, the square is rejected. The size of the square is controlled by the variable $h$, which is gradually reduced over time to simulate convergence.

The algorithm for the attack loop from [the paper](https://arxiv.org/pdf/1912.00049) is shown below. Although it is not necessary for you to understand everything now, we encourage you to try to parse each line and guess what is happening. This is good practice for future sections which use this kind of notation!

<table align='center'>
  <tbody>
    <tr>
      <td style={{verticalAlign: "top", textAlign: "right", paddingRight: "1em", userSelect: "none"}}>1</td>
      <td>$\hat{x} \leftarrow \text{init}(x), \quad l^* \leftarrow L(f(x), y), \quad i \leftarrow 1$</td>
    </tr>
    <tr>
      <td style={{verticalAlign: "top", textAlign: "right", paddingRight: "1em", userSelect: "none"}}>2</td>
      <td><b>while</b> $i < N$ and $\hat{x}$ is not adversarial <b>do</b></td>
    </tr>
    <tr>
      <td style={{verticalAlign: "top", textAlign: "right", paddingRight: "1em", userSelect: "none"}}>3</td>
      <td style={{paddingLeft: "2em"}}>$h^{(i)} \leftarrow$ side length of the square to modify (according to some schedule)</td>
    </tr>
    <tr>
      <td style={{verticalAlign: "top", textAlign: "right", paddingRight: "1em", userSelect: "none"}}>4</td>
      <td style={{paddingLeft: "2em"}}>$\delta \sim P(\epsilon, h^{(i)}, w, c, \hat{x}, x)$</td>
    </tr>
    <tr>
      <td style={{verticalAlign: "top", textAlign: "right", paddingRight: "1em", userSelect: "none"}}>5</td>
      <td style={{paddingLeft: "2em"}}>$\hat{x}_{\text{new}} \leftarrow \text{Project } \hat{x} + \delta \text{ onto } \{z \in \mathbb{R}^d : \|z - x\|_p \le \epsilon\} \cap [0, 1]^d$</td>
    </tr>
    <tr>
      <td style={{verticalAlign: "top", textAlign: "right", paddingRight: "1em", userSelect: "none"}}>6</td>
      <td style={{paddingLeft: "2em"}}>$l_{\text{new}} \leftarrow L(f(\hat{x}_{\text{new}}), y)$</td>
    </tr>
    <tr>
      <td style={{verticalAlign: "top", textAlign: "right", paddingRight: "1em", userSelect: "none"}}>7</td>
      <td style={{paddingLeft: "2em"}}><b>if</b> $l_{\text{new}} < l^*$ <b>then</b> $\hat{x} \leftarrow \hat{x}_{\text{new}}, l^* \leftarrow l_{\text{new}};$</td>
    </tr>
    <tr>
      <td style={{verticalAlign: "top", textAlign: "right", paddingRight: "1em", userSelect: "none"}}>8</td>
      <td style={{paddingLeft: "2em"}}>$i \leftarrow i + 1$</td>
    </tr>
    <tr>
      <td style={{verticalAlign: "top", textAlign: "right", paddingRight: "1em", userSelect: "none"}}>9</td>
      <td><b>end</b></td>
    </tr>
  </tbody>
</table>

## $L_\infty$ Square Attack

For the $L_\infty$ attack, the $\delta$ tensor from line 4 of the previous algorithm, is generated by picking a random location for the square on the image. Then for each color channel, a value for $\delta$ is randomly chosen uniformly between $-2\epsilon$ and $2 \epsilon$ where $\epsilon$ is the $L_\infty$ budget.

More concretely, $\delta$ can be visualized below assuming an input image with $32 \times 32$ pixels and 3 color channels. Note that although each color channel has the same square location, the value of the change at each color channel is different.

<p align="center">
  <img
    src="/square/example_square.png"
    alt="Example square from L_\infty square attack"
    style={{ maxWidth: "100%", height: "auto" }}
  />
  <br />
  <b>Fig. 2</b>
  <br />
  <em>Example $\delta$ for $L_\infty$ square attack</em>
</p>

Next this delta would be added to the current adversarial tensor before being projected such that all values are between 0 and 1 and the adversarial image is in the $L_\infty$ budget. For the $L_\infty$ attack this "projection" is done by clipping the image (similar to what you saw in the [FGSM/PGD section](https://xlabaisecurity.com/adversarial/adversarialimages/)).

### BONUS: $L_2$ Square Attack

Once again, we will note that the $L_2$ attack is quite technical and not necessary to understand for future sections of this course. If interested a brief writeup of the attack can be found below with more details in [the paper](https://arxiv.org/pdf/1912.00049) itself.

<Dropdown title="Understanding the $L_2$ Square Attack">

**The algorithm:**

<table align='center'>
  <tbody>
    <tr>
      <td style={{verticalAlign: "top", textAlign: "right", paddingRight: "1em", userSelect: "none"}}>1</td>
      <td>$\nu \leftarrow \hat{x} - x$</td>
    </tr>
    <tr>
      <td style={{verticalAlign: "top", textAlign: "right", paddingRight: "1em", userSelect: "none"}}>2</td>
      <td>sample uniformly $r_1, s_1, r_2, s_2 \in \{0, \dots, w - h\}$</td>
    </tr>
    <tr>
      <td style={{verticalAlign: "top", textAlign: "right", paddingRight: "1em", userSelect: "none"}}>3</td>
      <td>$W_1 := r_1 + 1 : r_1 + h, s_1 + 1 : s_1 + h, W_2 := r_2 + 1 : r_2 + h, s_2 + 1 : s_2 + h$</td>
    </tr>
    <tr>
      <td style={{verticalAlign: "top", textAlign: "right", paddingRight: "1em", userSelect: "none"}}>4</td>
      <td>$\epsilon^2_{\text{unused}} \leftarrow \epsilon^2 - \|\nu\|_2^2, \quad \eta^* \leftarrow \eta / \|\eta\|_2 \text{ with } \eta \text{ as in (2)}$</td>
    </tr>
    <tr>
      <td style={{verticalAlign: "top", textAlign: "right", paddingRight: "1em", userSelect: "none"}}>5</td>
      <td><b>for</b> $i = 1, \dots, c$ <b>do</b></td>
    </tr>
    <tr>
      <td style={{verticalAlign: "top", textAlign: "right", paddingRight: "1em", userSelect: "none"}}>6</td>
      <td style={{paddingLeft: "2em"}}>$\rho \leftarrow \text{Uniform}(\{-1, 1\})$</td>
    </tr>
    <tr>
      <td style={{verticalAlign: "top", textAlign: "right", paddingRight: "1em", userSelect: "none"}}>7</td>
      <td style={{paddingLeft: "2em"}}>$\nu_{\text{temp}} \leftarrow \rho\eta^* + \frac{\nu_{W_1, i}}{\|\nu_{W_1, i}\|_2}$</td>
    </tr>
    <tr>
      <td style={{verticalAlign: "top", textAlign: "right", paddingRight: "1em", userSelect: "none"}}>8</td>
      <td style={{paddingLeft: "2em"}}>$\epsilon^i_{\text{avail}} \leftarrow \sqrt{\|\nu_{W_1 \cup W_2, i}\|_2^2 + \frac{\epsilon^2_{\text{unused}}}{c}}$</td>
    </tr>
    <tr>
      <td style={{verticalAlign: "top", textAlign: "right", paddingRight: "1em", userSelect: "none"}}>9</td>
      <td style={{paddingLeft: "2em"}}>$\nu_{W_2, i} \leftarrow 0, \quad \nu_{W_1, i} \leftarrow \left( \frac{\nu_{\text{temp}}}{\|\nu_{\text{temp}}\|_2} \right) \epsilon^i_{\text{avail}}$</td>
    </tr>
    <tr>
      <td style={{verticalAlign: "top", textAlign: "right", paddingRight: "1em", userSelect: "none"}}>10</td>
      <td><b>end</b></td>
    </tr>
    <tr>
      <td style={{verticalAlign: "top", textAlign: "right", paddingRight: "1em", userSelect: "none"}}>11</td>
      <td>$\delta \leftarrow x + \nu - \hat{x}$</td>
    </tr>
  </tbody>
</table>

[@andriushchenko2020squareattackqueryefficientblackbox]

The $L_2$ Square Attack also uses the loop described above. However, its distribution aims to minimize the $L_2$ norm of the original and the adversarial image instead of the $L_\infty$ norm. This is a much more complicated task, since the $L_\infty$ norm is much easier to calculate than the $L_2$ norm. This distribution involves randomly choosing a square and dividing it into two halves, one negative, and one positive. Helper functions are used to create mound-like shapes in each of these half squares, with high values in the center, and radially decreasing perturbation values going outwards. Then, either this square or its transpose is chosen, and used to perturb the adversarial image.

</Dropdown>

<FeedbackButton />

<NextPageButton />

## References
