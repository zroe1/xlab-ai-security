---
title: "Introduction to LLMs"
description: "A brief background on the current paradigm of natural language processing"
---

While this course assumes some background in machine learning, we do not expect all users to have hands-on experience with running, fine-tuning and jailbreaking LLMs. To fill this gap, we provide some basic exercises we developed along with a list of resources if you are interested in exploring further.

## What You Need to Know

The transformer architecture is incredibly interesting and well-designed, but understanding it at a low level won't be necessary for our purposes. We want you to learn where the field is at, how attacks and defenses work, and what are the advantages and disadvantages of these approaches. To this end, you will need to understand how to pass input into a transformer, parse its output, and calculate loss.

We do not claim that having a lower level understanding of models cannot motivate better attacks or defenses. In fact, we are cautiously optimistic about approaches that leverage findings from [mechanistic interpretability](https://en.wikipedia.org/wiki/Mechanistic_interpretability) for robustness. These directions, however, remain speculative and are for the most part outside the scope of this course.

## Additional Resources

The exercises we provide are merely to give you the background necessary to implement famous and pedagogically useful attacks and defenses in this course. If you are interested in exploring LLMs at a deeper level (which we encourage), below you can find a list of our favorite resources.

1. **For an explanation on LLM scaling:** We reccomend [this video](https://www.youtube.com/watch?v=5eqRuVp65eY) for explanation of LLM scaling laws [@kaplan2020scalinglawsneurallanguage]. The idea that you can increase performance of LLMs though this kind of scaling has motivated development of modern LLMs.
