{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 20.0,
  "eval_steps": 500,
  "global_step": 2140,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.09389671361502347,
      "grad_norm": 60.454959869384766,
      "learning_rate": 1.8e-05,
      "loss": 14.4574,
      "step": 10
    },
    {
      "epoch": 0.18779342723004694,
      "grad_norm": 77.90790557861328,
      "learning_rate": 3.8e-05,
      "loss": 12.6742,
      "step": 20
    },
    {
      "epoch": 0.28169014084507044,
      "grad_norm": 50.57771682739258,
      "learning_rate": 5.8e-05,
      "loss": 8.2526,
      "step": 30
    },
    {
      "epoch": 0.3755868544600939,
      "grad_norm": 21.497737884521484,
      "learning_rate": 7.800000000000001e-05,
      "loss": 3.055,
      "step": 40
    },
    {
      "epoch": 0.4694835680751174,
      "grad_norm": 0.8972471952438354,
      "learning_rate": 9.8e-05,
      "loss": 0.5531,
      "step": 50
    },
    {
      "epoch": 0.5633802816901409,
      "grad_norm": 0.35200873017311096,
      "learning_rate": 9.999542463677584e-05,
      "loss": 0.4261,
      "step": 60
    },
    {
      "epoch": 0.6572769953051644,
      "grad_norm": 0.3161756098270416,
      "learning_rate": 9.997960964140947e-05,
      "loss": 0.352,
      "step": 70
    },
    {
      "epoch": 0.7511737089201878,
      "grad_norm": 0.3752012550830841,
      "learning_rate": 9.995250210037267e-05,
      "loss": 0.3859,
      "step": 80
    },
    {
      "epoch": 0.8450704225352113,
      "grad_norm": 0.2885894775390625,
      "learning_rate": 9.991410813842605e-05,
      "loss": 0.3455,
      "step": 90
    },
    {
      "epoch": 0.9389671361502347,
      "grad_norm": 0.27984726428985596,
      "learning_rate": 9.986443643041869e-05,
      "loss": 0.4461,
      "step": 100
    },
    {
      "epoch": 1.028169014084507,
      "grad_norm": 0.4525390565395355,
      "learning_rate": 9.980349819932798e-05,
      "loss": 0.4885,
      "step": 110
    },
    {
      "epoch": 1.1220657276995305,
      "grad_norm": 0.3569016456604004,
      "learning_rate": 9.973130721372402e-05,
      "loss": 0.3177,
      "step": 120
    },
    {
      "epoch": 1.215962441314554,
      "grad_norm": 0.3431348502635956,
      "learning_rate": 9.964787978465862e-05,
      "loss": 0.3157,
      "step": 130
    },
    {
      "epoch": 1.3098591549295775,
      "grad_norm": 0.3777875602245331,
      "learning_rate": 9.95532347619799e-05,
      "loss": 0.3532,
      "step": 140
    },
    {
      "epoch": 1.403755868544601,
      "grad_norm": 0.35179194808006287,
      "learning_rate": 9.944739353007344e-05,
      "loss": 0.337,
      "step": 150
    },
    {
      "epoch": 1.4976525821596245,
      "grad_norm": 0.41060948371887207,
      "learning_rate": 9.933038000303044e-05,
      "loss": 0.3517,
      "step": 160
    },
    {
      "epoch": 1.591549295774648,
      "grad_norm": 0.347320556640625,
      "learning_rate": 9.920222061924464e-05,
      "loss": 0.3421,
      "step": 170
    },
    {
      "epoch": 1.6854460093896715,
      "grad_norm": 0.3754725456237793,
      "learning_rate": 9.90629443354387e-05,
      "loss": 0.3126,
      "step": 180
    },
    {
      "epoch": 1.779342723004695,
      "grad_norm": 0.4479927122592926,
      "learning_rate": 9.891258262012161e-05,
      "loss": 0.3914,
      "step": 190
    },
    {
      "epoch": 1.8732394366197183,
      "grad_norm": 0.34976208209991455,
      "learning_rate": 9.875116944647863e-05,
      "loss": 0.3283,
      "step": 200
    },
    {
      "epoch": 1.9671361502347418,
      "grad_norm": 0.5145590305328369,
      "learning_rate": 9.857874128469527e-05,
      "loss": 0.3087,
      "step": 210
    },
    {
      "epoch": 2.056338028169014,
      "grad_norm": 0.4991927742958069,
      "learning_rate": 9.839533709371707e-05,
      "loss": 0.3196,
      "step": 220
    },
    {
      "epoch": 2.1502347417840375,
      "grad_norm": 0.36389005184173584,
      "learning_rate": 9.820099831244722e-05,
      "loss": 0.272,
      "step": 230
    },
    {
      "epoch": 2.244131455399061,
      "grad_norm": 0.5543842315673828,
      "learning_rate": 9.799576885038355e-05,
      "loss": 0.3459,
      "step": 240
    },
    {
      "epoch": 2.3380281690140845,
      "grad_norm": 0.46359962224960327,
      "learning_rate": 9.777969507769764e-05,
      "loss": 0.2844,
      "step": 250
    },
    {
      "epoch": 2.431924882629108,
      "grad_norm": 0.3877725899219513,
      "learning_rate": 9.755282581475769e-05,
      "loss": 0.3618,
      "step": 260
    },
    {
      "epoch": 2.5258215962441315,
      "grad_norm": 0.341370552778244,
      "learning_rate": 9.731521232109797e-05,
      "loss": 0.2926,
      "step": 270
    },
    {
      "epoch": 2.619718309859155,
      "grad_norm": 0.3567231297492981,
      "learning_rate": 9.706690828383704e-05,
      "loss": 0.4274,
      "step": 280
    },
    {
      "epoch": 2.7136150234741785,
      "grad_norm": 0.43636631965637207,
      "learning_rate": 9.680796980554759e-05,
      "loss": 0.2849,
      "step": 290
    },
    {
      "epoch": 2.807511737089202,
      "grad_norm": 0.411047101020813,
      "learning_rate": 9.653845539158032e-05,
      "loss": 0.3029,
      "step": 300
    },
    {
      "epoch": 2.9014084507042255,
      "grad_norm": 0.4297484755516052,
      "learning_rate": 9.625842593684521e-05,
      "loss": 0.3041,
      "step": 310
    },
    {
      "epoch": 2.995305164319249,
      "grad_norm": 0.47255179286003113,
      "learning_rate": 9.596794471205263e-05,
      "loss": 0.2824,
      "step": 320
    },
    {
      "epoch": 3.084507042253521,
      "grad_norm": 0.38673168420791626,
      "learning_rate": 9.566707734941781e-05,
      "loss": 0.3308,
      "step": 330
    },
    {
      "epoch": 3.1784037558685445,
      "grad_norm": 0.5026777386665344,
      "learning_rate": 9.53558918278317e-05,
      "loss": 0.3343,
      "step": 340
    },
    {
      "epoch": 3.272300469483568,
      "grad_norm": 0.3520938754081726,
      "learning_rate": 9.50344584575016e-05,
      "loss": 0.2775,
      "step": 350
    },
    {
      "epoch": 3.3661971830985915,
      "grad_norm": 0.5296797156333923,
      "learning_rate": 9.470284986406506e-05,
      "loss": 0.3741,
      "step": 360
    },
    {
      "epoch": 3.460093896713615,
      "grad_norm": 0.4054287075996399,
      "learning_rate": 9.43611409721806e-05,
      "loss": 0.2875,
      "step": 370
    },
    {
      "epoch": 3.5539906103286385,
      "grad_norm": 0.3761134743690491,
      "learning_rate": 9.400940898859905e-05,
      "loss": 0.2775,
      "step": 380
    },
    {
      "epoch": 3.647887323943662,
      "grad_norm": 0.4761453866958618,
      "learning_rate": 9.364773338471917e-05,
      "loss": 0.2925,
      "step": 390
    },
    {
      "epoch": 3.7417840375586855,
      "grad_norm": 0.551476240158081,
      "learning_rate": 9.32761958786317e-05,
      "loss": 0.2992,
      "step": 400
    },
    {
      "epoch": 3.835680751173709,
      "grad_norm": 0.4741365313529968,
      "learning_rate": 9.289488041665564e-05,
      "loss": 0.2981,
      "step": 410
    },
    {
      "epoch": 3.9295774647887325,
      "grad_norm": 0.5403462052345276,
      "learning_rate": 9.250387315437125e-05,
      "loss": 0.3237,
      "step": 420
    },
    {
      "epoch": 4.018779342723005,
      "grad_norm": 0.5364493131637573,
      "learning_rate": 9.210326243715376e-05,
      "loss": 0.291,
      "step": 430
    },
    {
      "epoch": 4.112676056338028,
      "grad_norm": 0.5179964303970337,
      "learning_rate": 9.16931387802123e-05,
      "loss": 0.2933,
      "step": 440
    },
    {
      "epoch": 4.206572769953052,
      "grad_norm": 0.5499313473701477,
      "learning_rate": 9.12735948481387e-05,
      "loss": 0.3252,
      "step": 450
    },
    {
      "epoch": 4.300469483568075,
      "grad_norm": 0.5297675728797913,
      "learning_rate": 9.084472543397052e-05,
      "loss": 0.3104,
      "step": 460
    },
    {
      "epoch": 4.394366197183099,
      "grad_norm": 0.5231853127479553,
      "learning_rate": 9.04066274377732e-05,
      "loss": 0.2798,
      "step": 470
    },
    {
      "epoch": 4.488262910798122,
      "grad_norm": 0.4459996521472931,
      "learning_rate": 8.995939984474624e-05,
      "loss": 0.296,
      "step": 480
    },
    {
      "epoch": 4.582159624413146,
      "grad_norm": 0.4316629469394684,
      "learning_rate": 8.950314370285811e-05,
      "loss": 0.2694,
      "step": 490
    },
    {
      "epoch": 4.676056338028169,
      "grad_norm": 0.7881554365158081,
      "learning_rate": 8.903796210001518e-05,
      "loss": 0.3013,
      "step": 500
    },
    {
      "epoch": 4.769953051643192,
      "grad_norm": 0.5283377766609192,
      "learning_rate": 8.856396014076977e-05,
      "loss": 0.3076,
      "step": 510
    },
    {
      "epoch": 4.863849765258216,
      "grad_norm": 0.5375545620918274,
      "learning_rate": 8.808124492257242e-05,
      "loss": 0.2556,
      "step": 520
    },
    {
      "epoch": 4.957746478873239,
      "grad_norm": 0.6131666302680969,
      "learning_rate": 8.758992551157401e-05,
      "loss": 0.2884,
      "step": 530
    },
    {
      "epoch": 5.046948356807512,
      "grad_norm": 0.46132805943489075,
      "learning_rate": 8.70901129179831e-05,
      "loss": 0.251,
      "step": 540
    },
    {
      "epoch": 5.140845070422535,
      "grad_norm": 0.5643138289451599,
      "learning_rate": 8.658192007098377e-05,
      "loss": 0.2965,
      "step": 550
    },
    {
      "epoch": 5.234741784037559,
      "grad_norm": 0.47628599405288696,
      "learning_rate": 8.606546179322026e-05,
      "loss": 0.2672,
      "step": 560
    },
    {
      "epoch": 5.328638497652582,
      "grad_norm": 0.539385199546814,
      "learning_rate": 8.554085477485337e-05,
      "loss": 0.2692,
      "step": 570
    },
    {
      "epoch": 5.422535211267606,
      "grad_norm": 0.7306914925575256,
      "learning_rate": 8.50082175471953e-05,
      "loss": 0.2845,
      "step": 580
    },
    {
      "epoch": 5.516431924882629,
      "grad_norm": 0.5539339184761047,
      "learning_rate": 8.44676704559283e-05,
      "loss": 0.2761,
      "step": 590
    },
    {
      "epoch": 5.610328638497653,
      "grad_norm": 0.6338185667991638,
      "learning_rate": 8.39193356339133e-05,
      "loss": 0.3438,
      "step": 600
    },
    {
      "epoch": 5.704225352112676,
      "grad_norm": 0.46598687767982483,
      "learning_rate": 8.336333697359495e-05,
      "loss": 0.2519,
      "step": 610
    },
    {
      "epoch": 5.7981220657277,
      "grad_norm": 0.6416781544685364,
      "learning_rate": 8.279980009900892e-05,
      "loss": 0.2608,
      "step": 620
    },
    {
      "epoch": 5.892018779342723,
      "grad_norm": 0.42550116777420044,
      "learning_rate": 8.222885233739801e-05,
      "loss": 0.2651,
      "step": 630
    },
    {
      "epoch": 5.985915492957746,
      "grad_norm": 0.5981584787368774,
      "learning_rate": 8.165062269044353e-05,
      "loss": 0.2981,
      "step": 640
    },
    {
      "epoch": 6.075117370892019,
      "grad_norm": 0.5082617402076721,
      "learning_rate": 8.106524180511816e-05,
      "loss": 0.3432,
      "step": 650
    },
    {
      "epoch": 6.169014084507042,
      "grad_norm": 0.5505973696708679,
      "learning_rate": 8.047284194416724e-05,
      "loss": 0.2505,
      "step": 660
    },
    {
      "epoch": 6.262910798122066,
      "grad_norm": 0.5671671628952026,
      "learning_rate": 7.987355695622493e-05,
      "loss": 0.2406,
      "step": 670
    },
    {
      "epoch": 6.356807511737089,
      "grad_norm": 0.6316734552383423,
      "learning_rate": 7.926752224557194e-05,
      "loss": 0.2568,
      "step": 680
    },
    {
      "epoch": 6.450704225352113,
      "grad_norm": 0.5854356288909912,
      "learning_rate": 7.865487474154203e-05,
      "loss": 0.2809,
      "step": 690
    },
    {
      "epoch": 6.544600938967136,
      "grad_norm": 0.6646016240119934,
      "learning_rate": 7.803575286758364e-05,
      "loss": 0.277,
      "step": 700
    },
    {
      "epoch": 6.63849765258216,
      "grad_norm": 0.5736809372901917,
      "learning_rate": 7.741029650998415e-05,
      "loss": 0.2721,
      "step": 710
    },
    {
      "epoch": 6.732394366197183,
      "grad_norm": 0.9605832695960999,
      "learning_rate": 7.677864698626352e-05,
      "loss": 0.3,
      "step": 720
    },
    {
      "epoch": 6.826291079812207,
      "grad_norm": 0.5379679799079895,
      "learning_rate": 7.614094701324457e-05,
      "loss": 0.2579,
      "step": 730
    },
    {
      "epoch": 6.92018779342723,
      "grad_norm": 0.48119044303894043,
      "learning_rate": 7.549734067480714e-05,
      "loss": 0.2442,
      "step": 740
    },
    {
      "epoch": 7.009389671361502,
      "grad_norm": 0.45927008986473083,
      "learning_rate": 7.48479733893333e-05,
      "loss": 0.2286,
      "step": 750
    },
    {
      "epoch": 7.103286384976526,
      "grad_norm": 0.5888004302978516,
      "learning_rate": 7.419299187685108e-05,
      "loss": 0.256,
      "step": 760
    },
    {
      "epoch": 7.197183098591549,
      "grad_norm": 0.530705988407135,
      "learning_rate": 7.353254412588413e-05,
      "loss": 0.2426,
      "step": 770
    },
    {
      "epoch": 7.291079812206573,
      "grad_norm": 0.6315011978149414,
      "learning_rate": 7.286677936001472e-05,
      "loss": 0.258,
      "step": 780
    },
    {
      "epoch": 7.384976525821596,
      "grad_norm": 0.7140355706214905,
      "learning_rate": 7.219584800416768e-05,
      "loss": 0.2545,
      "step": 790
    },
    {
      "epoch": 7.47887323943662,
      "grad_norm": 0.7116454243659973,
      "learning_rate": 7.151990165062298e-05,
      "loss": 0.2247,
      "step": 800
    },
    {
      "epoch": 7.572769953051643,
      "grad_norm": 0.6650062799453735,
      "learning_rate": 7.083909302476453e-05,
      "loss": 0.2924,
      "step": 810
    },
    {
      "epoch": 7.666666666666667,
      "grad_norm": 0.7194591760635376,
      "learning_rate": 7.015357595057282e-05,
      "loss": 0.2657,
      "step": 820
    },
    {
      "epoch": 7.76056338028169,
      "grad_norm": 0.5679075717926025,
      "learning_rate": 6.946350531586959e-05,
      "loss": 0.2454,
      "step": 830
    },
    {
      "epoch": 7.854460093896714,
      "grad_norm": 0.5924743413925171,
      "learning_rate": 6.876903703732193e-05,
      "loss": 0.2827,
      "step": 840
    },
    {
      "epoch": 7.948356807511737,
      "grad_norm": 0.5478681325912476,
      "learning_rate": 6.807032802521402e-05,
      "loss": 0.2342,
      "step": 850
    },
    {
      "epoch": 8.03755868544601,
      "grad_norm": 0.47274112701416016,
      "learning_rate": 6.736753614799438e-05,
      "loss": 0.2528,
      "step": 860
    },
    {
      "epoch": 8.131455399061032,
      "grad_norm": 0.5593766570091248,
      "learning_rate": 6.666082019660645e-05,
      "loss": 0.245,
      "step": 870
    },
    {
      "epoch": 8.225352112676056,
      "grad_norm": 0.7316601872444153,
      "learning_rate": 6.595033984861105e-05,
      "loss": 0.2501,
      "step": 880
    },
    {
      "epoch": 8.31924882629108,
      "grad_norm": 0.6126885414123535,
      "learning_rate": 6.523625563210824e-05,
      "loss": 0.2121,
      "step": 890
    },
    {
      "epoch": 8.413145539906104,
      "grad_norm": 0.6328012943267822,
      "learning_rate": 6.451872888946713e-05,
      "loss": 0.282,
      "step": 900
    },
    {
      "epoch": 8.507042253521126,
      "grad_norm": 0.6243373155593872,
      "learning_rate": 6.379792174087175e-05,
      "loss": 0.2372,
      "step": 910
    },
    {
      "epoch": 8.60093896713615,
      "grad_norm": 0.7185751795768738,
      "learning_rate": 6.307399704769099e-05,
      "loss": 0.2824,
      "step": 920
    },
    {
      "epoch": 8.694835680751174,
      "grad_norm": 0.5747883319854736,
      "learning_rate": 6.234711837568137e-05,
      "loss": 0.2089,
      "step": 930
    },
    {
      "epoch": 8.788732394366198,
      "grad_norm": 0.571742832660675,
      "learning_rate": 6.161744995803037e-05,
      "loss": 0.2416,
      "step": 940
    },
    {
      "epoch": 8.88262910798122,
      "grad_norm": 0.7681402564048767,
      "learning_rate": 6.088515665824909e-05,
      "loss": 0.2535,
      "step": 950
    },
    {
      "epoch": 8.976525821596244,
      "grad_norm": 0.6675851345062256,
      "learning_rate": 6.015040393292257e-05,
      "loss": 0.2549,
      "step": 960
    },
    {
      "epoch": 9.065727699530516,
      "grad_norm": 0.5269020199775696,
      "learning_rate": 5.941335779432596e-05,
      "loss": 0.2405,
      "step": 970
    },
    {
      "epoch": 9.15962441314554,
      "grad_norm": 0.5460214614868164,
      "learning_rate": 5.86741847729152e-05,
      "loss": 0.2266,
      "step": 980
    },
    {
      "epoch": 9.253521126760564,
      "grad_norm": 0.6947652101516724,
      "learning_rate": 5.793305187970062e-05,
      "loss": 0.2169,
      "step": 990
    },
    {
      "epoch": 9.347417840375586,
      "grad_norm": 0.7553001642227173,
      "learning_rate": 5.719012656851199e-05,
      "loss": 0.2649,
      "step": 1000
    },
    {
      "epoch": 9.44131455399061,
      "grad_norm": 0.6847416758537292,
      "learning_rate": 5.644557669816345e-05,
      "loss": 0.2285,
      "step": 1010
    },
    {
      "epoch": 9.535211267605634,
      "grad_norm": 0.720052182674408,
      "learning_rate": 5.569957049452703e-05,
      "loss": 0.2307,
      "step": 1020
    },
    {
      "epoch": 9.629107981220658,
      "grad_norm": 0.42458364367485046,
      "learning_rate": 5.495227651252315e-05,
      "loss": 0.2202,
      "step": 1030
    },
    {
      "epoch": 9.72300469483568,
      "grad_norm": 0.5090242028236389,
      "learning_rate": 5.4203863598036753e-05,
      "loss": 0.2612,
      "step": 1040
    },
    {
      "epoch": 9.816901408450704,
      "grad_norm": 0.785102128982544,
      "learning_rate": 5.345450084976786e-05,
      "loss": 0.2351,
      "step": 1050
    },
    {
      "epoch": 9.910798122065728,
      "grad_norm": 0.7260281443595886,
      "learning_rate": 5.2704357581024844e-05,
      "loss": 0.208,
      "step": 1060
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.1268649101257324,
      "learning_rate": 5.195360328146921e-05,
      "loss": 0.2327,
      "step": 1070
    },
    {
      "epoch": 10.093896713615024,
      "grad_norm": 0.6787348985671997,
      "learning_rate": 5.1202407578820685e-05,
      "loss": 0.2278,
      "step": 1080
    },
    {
      "epoch": 10.187793427230046,
      "grad_norm": 0.7170751690864563,
      "learning_rate": 5.0450940200530915e-05,
      "loss": 0.25,
      "step": 1090
    },
    {
      "epoch": 10.28169014084507,
      "grad_norm": 0.8220158219337463,
      "learning_rate": 4.96993709354348e-05,
      "loss": 0.2092,
      "step": 1100
    },
    {
      "epoch": 10.375586854460094,
      "grad_norm": 0.5391328930854797,
      "learning_rate": 4.8947869595387815e-05,
      "loss": 0.2136,
      "step": 1110
    },
    {
      "epoch": 10.469483568075118,
      "grad_norm": 0.8809152245521545,
      "learning_rate": 4.8196605976898296e-05,
      "loss": 0.2021,
      "step": 1120
    },
    {
      "epoch": 10.56338028169014,
      "grad_norm": 0.6494696736335754,
      "learning_rate": 4.7445749822763034e-05,
      "loss": 0.2114,
      "step": 1130
    },
    {
      "epoch": 10.657276995305164,
      "grad_norm": 0.7016865611076355,
      "learning_rate": 4.669547078371504e-05,
      "loss": 0.2231,
      "step": 1140
    },
    {
      "epoch": 10.751173708920188,
      "grad_norm": 0.7006921172142029,
      "learning_rate": 4.5945938380092205e-05,
      "loss": 0.2219,
      "step": 1150
    },
    {
      "epoch": 10.845070422535212,
      "grad_norm": 0.78155517578125,
      "learning_rate": 4.5197321963535335e-05,
      "loss": 0.198,
      "step": 1160
    },
    {
      "epoch": 10.938967136150234,
      "grad_norm": 0.5851372480392456,
      "learning_rate": 4.4449790678724304e-05,
      "loss": 0.2496,
      "step": 1170
    },
    {
      "epoch": 11.028169014084508,
      "grad_norm": 0.39673876762390137,
      "learning_rate": 4.3703513425161054e-05,
      "loss": 0.2975,
      "step": 1180
    },
    {
      "epoch": 11.12206572769953,
      "grad_norm": 0.6211768984794617,
      "learning_rate": 4.2958658819007816e-05,
      "loss": 0.2049,
      "step": 1190
    },
    {
      "epoch": 11.215962441314554,
      "grad_norm": 0.7529537081718445,
      "learning_rate": 4.221539515498952e-05,
      "loss": 0.1873,
      "step": 1200
    },
    {
      "epoch": 11.309859154929578,
      "grad_norm": 0.9717706441879272,
      "learning_rate": 4.147389036836881e-05,
      "loss": 0.2431,
      "step": 1210
    },
    {
      "epoch": 11.4037558685446,
      "grad_norm": 0.7021225690841675,
      "learning_rate": 4.073431199700218e-05,
      "loss": 0.2352,
      "step": 1220
    },
    {
      "epoch": 11.497652582159624,
      "grad_norm": 0.8027157187461853,
      "learning_rate": 3.9996827143486016e-05,
      "loss": 0.2192,
      "step": 1230
    },
    {
      "epoch": 11.591549295774648,
      "grad_norm": 0.763683021068573,
      "learning_rate": 3.926160243740079e-05,
      "loss": 0.1877,
      "step": 1240
    },
    {
      "epoch": 11.685446009389672,
      "grad_norm": 0.8000413179397583,
      "learning_rate": 3.852880399766243e-05,
      "loss": 0.2727,
      "step": 1250
    },
    {
      "epoch": 11.779342723004694,
      "grad_norm": 0.767859935760498,
      "learning_rate": 3.779859739498883e-05,
      "loss": 0.2085,
      "step": 1260
    },
    {
      "epoch": 11.873239436619718,
      "grad_norm": 0.6282689571380615,
      "learning_rate": 3.707114761449031e-05,
      "loss": 0.1907,
      "step": 1270
    },
    {
      "epoch": 11.967136150234742,
      "grad_norm": 0.5831199288368225,
      "learning_rate": 3.634661901839231e-05,
      "loss": 0.1842,
      "step": 1280
    },
    {
      "epoch": 12.056338028169014,
      "grad_norm": 0.8016899228096008,
      "learning_rate": 3.562517530889902e-05,
      "loss": 0.2049,
      "step": 1290
    },
    {
      "epoch": 12.150234741784038,
      "grad_norm": 0.7870097756385803,
      "learning_rate": 3.490697949120586e-05,
      "loss": 0.201,
      "step": 1300
    },
    {
      "epoch": 12.244131455399062,
      "grad_norm": 0.778697669506073,
      "learning_rate": 3.4192193836669704e-05,
      "loss": 0.2163,
      "step": 1310
    },
    {
      "epoch": 12.338028169014084,
      "grad_norm": 0.9723902940750122,
      "learning_rate": 3.348097984614474e-05,
      "loss": 0.2548,
      "step": 1320
    },
    {
      "epoch": 12.431924882629108,
      "grad_norm": 0.6673269867897034,
      "learning_rate": 3.277349821349243e-05,
      "loss": 0.2313,
      "step": 1330
    },
    {
      "epoch": 12.525821596244132,
      "grad_norm": 1.011675477027893,
      "learning_rate": 3.206990878927395e-05,
      "loss": 0.2098,
      "step": 1340
    },
    {
      "epoch": 12.619718309859154,
      "grad_norm": 0.7087211012840271,
      "learning_rate": 3.1370370544633e-05,
      "loss": 0.1904,
      "step": 1350
    },
    {
      "epoch": 12.713615023474178,
      "grad_norm": 0.8646826148033142,
      "learning_rate": 3.0675041535377405e-05,
      "loss": 0.1964,
      "step": 1360
    },
    {
      "epoch": 12.807511737089202,
      "grad_norm": 0.9794247150421143,
      "learning_rate": 2.998407886626743e-05,
      "loss": 0.2225,
      "step": 1370
    },
    {
      "epoch": 12.901408450704226,
      "grad_norm": 0.7245656847953796,
      "learning_rate": 2.9297638655519177e-05,
      "loss": 0.1736,
      "step": 1380
    },
    {
      "epoch": 12.995305164319248,
      "grad_norm": 0.7952207922935486,
      "learning_rate": 2.8615875999530682e-05,
      "loss": 0.1968,
      "step": 1390
    },
    {
      "epoch": 13.084507042253522,
      "grad_norm": 0.7158299088478088,
      "learning_rate": 2.7938944937838923e-05,
      "loss": 0.2239,
      "step": 1400
    },
    {
      "epoch": 13.178403755868544,
      "grad_norm": 0.6568731665611267,
      "learning_rate": 2.7266998418315792e-05,
      "loss": 0.1803,
      "step": 1410
    },
    {
      "epoch": 13.272300469483568,
      "grad_norm": 0.9046452045440674,
      "learning_rate": 2.6600188262610392e-05,
      "loss": 0.1911,
      "step": 1420
    },
    {
      "epoch": 13.366197183098592,
      "grad_norm": 0.8576998114585876,
      "learning_rate": 2.5938665131846134e-05,
      "loss": 0.1957,
      "step": 1430
    },
    {
      "epoch": 13.460093896713616,
      "grad_norm": 1.0103981494903564,
      "learning_rate": 2.5282578492579922e-05,
      "loss": 0.207,
      "step": 1440
    },
    {
      "epoch": 13.553990610328638,
      "grad_norm": 0.7557022571563721,
      "learning_rate": 2.4632076583031106e-05,
      "loss": 0.191,
      "step": 1450
    },
    {
      "epoch": 13.647887323943662,
      "grad_norm": 0.9011184573173523,
      "learning_rate": 2.3987306379588142e-05,
      "loss": 0.1776,
      "step": 1460
    },
    {
      "epoch": 13.741784037558686,
      "grad_norm": 0.8822493553161621,
      "learning_rate": 2.3348413563600325e-05,
      "loss": 0.2088,
      "step": 1470
    },
    {
      "epoch": 13.835680751173708,
      "grad_norm": 0.8163147568702698,
      "learning_rate": 2.2715542488462045e-05,
      "loss": 0.2227,
      "step": 1480
    },
    {
      "epoch": 13.929577464788732,
      "grad_norm": 0.7890385985374451,
      "learning_rate": 2.2088836146997228e-05,
      "loss": 0.2022,
      "step": 1490
    },
    {
      "epoch": 14.018779342723004,
      "grad_norm": 0.8252459168434143,
      "learning_rate": 2.1468436139150984e-05,
      "loss": 0.1972,
      "step": 1500
    },
    {
      "epoch": 14.112676056338028,
      "grad_norm": 0.8852503299713135,
      "learning_rate": 2.0854482639996166e-05,
      "loss": 0.1952,
      "step": 1510
    },
    {
      "epoch": 14.206572769953052,
      "grad_norm": 0.8287756443023682,
      "learning_rate": 2.0247114368061765e-05,
      "loss": 0.1852,
      "step": 1520
    },
    {
      "epoch": 14.300469483568076,
      "grad_norm": 0.8487634658813477,
      "learning_rate": 1.9646468553990388e-05,
      "loss": 0.1935,
      "step": 1530
    },
    {
      "epoch": 14.394366197183098,
      "grad_norm": 0.6824117302894592,
      "learning_rate": 1.9052680909532056e-05,
      "loss": 0.2002,
      "step": 1540
    },
    {
      "epoch": 14.488262910798122,
      "grad_norm": 0.929850697517395,
      "learning_rate": 1.8465885596880883e-05,
      "loss": 0.2037,
      "step": 1550
    },
    {
      "epoch": 14.582159624413146,
      "grad_norm": 0.6272647380828857,
      "learning_rate": 1.788621519836228e-05,
      "loss": 0.2279,
      "step": 1560
    },
    {
      "epoch": 14.676056338028168,
      "grad_norm": 0.895630419254303,
      "learning_rate": 1.731380068647675e-05,
      "loss": 0.1753,
      "step": 1570
    },
    {
      "epoch": 14.769953051643192,
      "grad_norm": 0.7492486238479614,
      "learning_rate": 1.6748771394307585e-05,
      "loss": 0.2023,
      "step": 1580
    },
    {
      "epoch": 14.863849765258216,
      "grad_norm": 0.9354631304740906,
      "learning_rate": 1.619125498629904e-05,
      "loss": 0.1939,
      "step": 1590
    },
    {
      "epoch": 14.95774647887324,
      "grad_norm": 0.6819450259208679,
      "learning_rate": 1.5641377429411287e-05,
      "loss": 0.1823,
      "step": 1600
    },
    {
      "epoch": 15.046948356807512,
      "grad_norm": 0.7748666405677795,
      "learning_rate": 1.5099262964659222e-05,
      "loss": 0.1802,
      "step": 1610
    },
    {
      "epoch": 15.140845070422536,
      "grad_norm": 1.1218663454055786,
      "learning_rate": 1.456503407904095e-05,
      "loss": 0.1961,
      "step": 1620
    },
    {
      "epoch": 15.234741784037558,
      "grad_norm": 0.8037392497062683,
      "learning_rate": 1.4038811477862745e-05,
      "loss": 0.2271,
      "step": 1630
    },
    {
      "epoch": 15.328638497652582,
      "grad_norm": 0.8980239629745483,
      "learning_rate": 1.3520714057466516e-05,
      "loss": 0.1737,
      "step": 1640
    },
    {
      "epoch": 15.422535211267606,
      "grad_norm": 0.7539494037628174,
      "learning_rate": 1.3010858878366005e-05,
      "loss": 0.1649,
      "step": 1650
    },
    {
      "epoch": 15.51643192488263,
      "grad_norm": 0.8618226051330566,
      "learning_rate": 1.250936113879781e-05,
      "loss": 0.1991,
      "step": 1660
    },
    {
      "epoch": 15.610328638497652,
      "grad_norm": 0.7329404354095459,
      "learning_rate": 1.201633414869307e-05,
      "loss": 0.1995,
      "step": 1670
    },
    {
      "epoch": 15.704225352112676,
      "grad_norm": 0.8986883759498596,
      "learning_rate": 1.1531889304075933e-05,
      "loss": 0.1724,
      "step": 1680
    },
    {
      "epoch": 15.7981220657277,
      "grad_norm": 1.0114041566848755,
      "learning_rate": 1.1056136061894384e-05,
      "loss": 0.2228,
      "step": 1690
    },
    {
      "epoch": 15.892018779342724,
      "grad_norm": 0.8232515454292297,
      "learning_rate": 1.0589181915289186e-05,
      "loss": 0.1877,
      "step": 1700
    },
    {
      "epoch": 15.985915492957746,
      "grad_norm": 0.9904060959815979,
      "learning_rate": 1.0131132369306612e-05,
      "loss": 0.1879,
      "step": 1710
    },
    {
      "epoch": 16.07511737089202,
      "grad_norm": 0.9506320953369141,
      "learning_rate": 9.682090917060227e-06,
      "loss": 0.1711,
      "step": 1720
    },
    {
      "epoch": 16.169014084507044,
      "grad_norm": 0.9041711091995239,
      "learning_rate": 9.242159016347396e-06,
      "loss": 0.2132,
      "step": 1730
    },
    {
      "epoch": 16.262910798122064,
      "grad_norm": 0.9172189235687256,
      "learning_rate": 8.811436066725593e-06,
      "loss": 0.1525,
      "step": 1740
    },
    {
      "epoch": 16.356807511737088,
      "grad_norm": 0.9103149175643921,
      "learning_rate": 8.390019387053716e-06,
      "loss": 0.1879,
      "step": 1750
    },
    {
      "epoch": 16.450704225352112,
      "grad_norm": 0.9490916728973389,
      "learning_rate": 7.978004193503686e-06,
      "loss": 0.2155,
      "step": 1760
    },
    {
      "epoch": 16.544600938967136,
      "grad_norm": 0.8694343566894531,
      "learning_rate": 7.575483578046816e-06,
      "loss": 0.185,
      "step": 1770
    },
    {
      "epoch": 16.63849765258216,
      "grad_norm": 0.6092562079429626,
      "learning_rate": 7.182548487420554e-06,
      "loss": 0.1574,
      "step": 1780
    },
    {
      "epoch": 16.732394366197184,
      "grad_norm": 0.675382673740387,
      "learning_rate": 6.799287702579515e-06,
      "loss": 0.1859,
      "step": 1790
    },
    {
      "epoch": 16.826291079812208,
      "grad_norm": 0.8284208178520203,
      "learning_rate": 6.425787818636131e-06,
      "loss": 0.1901,
      "step": 1800
    },
    {
      "epoch": 16.920187793427232,
      "grad_norm": 0.7566925883293152,
      "learning_rate": 6.062133225295108e-06,
      "loss": 0.2002,
      "step": 1810
    },
    {
      "epoch": 17.009389671361504,
      "grad_norm": 0.8237168192863464,
      "learning_rate": 5.708406087786045e-06,
      "loss": 0.1913,
      "step": 1820
    },
    {
      "epoch": 17.103286384976524,
      "grad_norm": 0.7757981419563293,
      "learning_rate": 5.364686328298912e-06,
      "loss": 0.1797,
      "step": 1830
    },
    {
      "epoch": 17.197183098591548,
      "grad_norm": 0.8963085412979126,
      "learning_rate": 5.031051607926096e-06,
      "loss": 0.2075,
      "step": 1840
    },
    {
      "epoch": 17.291079812206572,
      "grad_norm": 0.7448504567146301,
      "learning_rate": 4.707577309115441e-06,
      "loss": 0.1656,
      "step": 1850
    },
    {
      "epoch": 17.384976525821596,
      "grad_norm": 0.8213053345680237,
      "learning_rate": 4.394336518638098e-06,
      "loss": 0.2023,
      "step": 1860
    },
    {
      "epoch": 17.47887323943662,
      "grad_norm": 0.7022605538368225,
      "learning_rate": 4.091400011075092e-06,
      "loss": 0.173,
      "step": 1870
    },
    {
      "epoch": 17.572769953051644,
      "grad_norm": 0.8134967088699341,
      "learning_rate": 3.7988362328263138e-06,
      "loss": 0.2078,
      "step": 1880
    },
    {
      "epoch": 17.666666666666668,
      "grad_norm": 0.8345993161201477,
      "learning_rate": 3.5167112866454745e-06,
      "loss": 0.1613,
      "step": 1890
    },
    {
      "epoch": 17.760563380281692,
      "grad_norm": 0.7922258973121643,
      "learning_rate": 3.2450889167046917e-06,
      "loss": 0.1482,
      "step": 1900
    },
    {
      "epoch": 17.854460093896712,
      "grad_norm": 1.0938701629638672,
      "learning_rate": 2.9840304941919415e-06,
      "loss": 0.2288,
      "step": 1910
    },
    {
      "epoch": 17.948356807511736,
      "grad_norm": 0.8462563753128052,
      "learning_rate": 2.733595003444622e-06,
      "loss": 0.1906,
      "step": 1920
    },
    {
      "epoch": 18.037558685446008,
      "grad_norm": 0.8653659224510193,
      "learning_rate": 2.493839028622502e-06,
      "loss": 0.1859,
      "step": 1930
    },
    {
      "epoch": 18.131455399061032,
      "grad_norm": 0.7467392086982727,
      "learning_rate": 2.264816740922904e-06,
      "loss": 0.161,
      "step": 1940
    },
    {
      "epoch": 18.225352112676056,
      "grad_norm": 0.8824815154075623,
      "learning_rate": 2.04657988634106e-06,
      "loss": 0.1714,
      "step": 1950
    },
    {
      "epoch": 18.31924882629108,
      "grad_norm": 0.7703040242195129,
      "learning_rate": 1.8391777739785455e-06,
      "loss": 0.2096,
      "step": 1960
    },
    {
      "epoch": 18.413145539906104,
      "grad_norm": 1.0786542892456055,
      "learning_rate": 1.6426572649021476e-06,
      "loss": 0.1919,
      "step": 1970
    },
    {
      "epoch": 18.507042253521128,
      "grad_norm": 0.7530267238616943,
      "learning_rate": 1.4570627615559718e-06,
      "loss": 0.1877,
      "step": 1980
    },
    {
      "epoch": 18.600938967136152,
      "grad_norm": 0.7346935272216797,
      "learning_rate": 1.2824361977290477e-06,
      "loss": 0.206,
      "step": 1990
    },
    {
      "epoch": 18.694835680751172,
      "grad_norm": 0.9831219911575317,
      "learning_rate": 1.1188170290805933e-06,
      "loss": 0.1934,
      "step": 2000
    },
    {
      "epoch": 18.788732394366196,
      "grad_norm": 0.8287941813468933,
      "learning_rate": 9.662422242253887e-07,
      "loss": 0.1795,
      "step": 2010
    },
    {
      "epoch": 18.88262910798122,
      "grad_norm": 0.8965355157852173,
      "learning_rate": 8.247462563808817e-07,
      "loss": 0.1939,
      "step": 2020
    },
    {
      "epoch": 18.976525821596244,
      "grad_norm": 0.6626517176628113,
      "learning_rate": 6.94361095578272e-07,
      "loss": 0.1734,
      "step": 2030
    },
    {
      "epoch": 19.065727699530516,
      "grad_norm": 1.0697085857391357,
      "learning_rate": 5.751162014390632e-07,
      "loss": 0.1913,
      "step": 2040
    },
    {
      "epoch": 19.15962441314554,
      "grad_norm": 0.7524526715278625,
      "learning_rate": 4.670385165188806e-07,
      "loss": 0.1971,
      "step": 2050
    },
    {
      "epoch": 19.253521126760564,
      "grad_norm": 0.7433270812034607,
      "learning_rate": 3.7015246021999684e-07,
      "loss": 0.1834,
      "step": 2060
    },
    {
      "epoch": 19.347417840375588,
      "grad_norm": 0.8104217052459717,
      "learning_rate": 2.844799232739115e-07,
      "loss": 0.1937,
      "step": 2070
    },
    {
      "epoch": 19.441314553990612,
      "grad_norm": 0.9078415632247925,
      "learning_rate": 2.1004026279533018e-07,
      "loss": 0.2167,
      "step": 2080
    },
    {
      "epoch": 19.535211267605632,
      "grad_norm": 0.91117262840271,
      "learning_rate": 1.4685029790851291e-07,
      "loss": 0.184,
      "step": 2090
    },
    {
      "epoch": 19.629107981220656,
      "grad_norm": 0.8672709465026855,
      "learning_rate": 9.492430594715274e-08,
      "loss": 0.1853,
      "step": 2100
    },
    {
      "epoch": 19.72300469483568,
      "grad_norm": 0.8832637071609497,
      "learning_rate": 5.4274019228484077e-08,
      "loss": 0.1979,
      "step": 2110
    },
    {
      "epoch": 19.816901408450704,
      "grad_norm": 0.8425625562667847,
      "learning_rate": 2.4908622402469717e-08,
      "loss": 0.1578,
      "step": 2120
    },
    {
      "epoch": 19.910798122065728,
      "grad_norm": 0.8259325623512268,
      "learning_rate": 6.834750376549792e-09,
      "loss": 0.1569,
      "step": 2130
    },
    {
      "epoch": 20.0,
      "grad_norm": 1.5767159461975098,
      "learning_rate": 5.6486816596423854e-11,
      "loss": 0.1853,
      "step": 2140
    }
  ],
  "logging_steps": 10,
  "max_steps": 2140,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.4798386436096e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
