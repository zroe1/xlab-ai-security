{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b32503e-255a-4191-9fc2-b7bfa65874f4",
   "metadata": {},
   "source": [
    "# Introduction to Adversarial Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b6a1ba-a70f-4246-8d8a-6826bb6997ee",
   "metadata": {},
   "source": [
    "# 1. Loading a CNN\n",
    "To save time, we will use a pretrained CNN (on the CIFAR-10 dataset) in order to test various adversarial methods. It has a straight-forward architecture, which is shown below. To save having to store the model architecture as a file, only the weights can be stored, and the model architecture can be replicated as follows.\n",
    "\n",
    "Our utility library contains the majority of the following functions. They will not have to be implemented in future notebooks.\n",
    "\n",
    "### Task 1\n",
    "Build the model using the provided layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bed9cdc-8cf2-4fcd-9603-b9b83c959122",
   "metadata": {},
   "source": [
    "\n",
    "<details>\n",
    "<summary>üîê <b>Solution for Task #1</b></summary>\n",
    "\n",
    "```python\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = Conv2d(3, 16, kernel_size = 3, padding = 1)\n",
    "        self.pooling = MaxPool2d(2,2)\n",
    "        self.dropout = Dropout(p=0.3)\n",
    "        self.conv2 = Conv2d(16, 32, kernel_size = 3, padding = 1)\n",
    "        self.relu = ReLU()\n",
    "        self.flatten = Flatten()\n",
    "        self.linear1 = Linear(2048, 128)\n",
    "        self.linear2 = Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) #Convolution layer\n",
    "        x = self.pooling(x) #Max Pooling Layer\n",
    "        x = self.dropout(x) #Dropout Layer\n",
    "        x = self.conv2(x) #Second Convolution Layer\n",
    "        x = self.pooling(x) #Second Pooling Layer\n",
    "        x = self.flatten(x) #Flatten Layer\n",
    "        x = self.relu(self.linear1(x)) #Regular Layer\n",
    "        x = self.dropout(x) #Second Dropout Layer\n",
    "        x = self.linear2(x) #Output Layer\n",
    "        return x\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03a9ff1-762c-454b-a0bb-4a0513952fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, ReLU, Dropout #All of the necessary layers for this model\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = Conv2d(3, 16, kernel_size = 3, padding = 1)\n",
    "        self.pooling = MaxPool2d(2,2)\n",
    "        self.dropout = Dropout(p=0.3)\n",
    "        self.conv2 = Conv2d(16, 32, kernel_size = 3, padding = 1)\n",
    "        self.relu = ReLU()\n",
    "        self.flatten = Flatten()\n",
    "        self.linear1 = Linear(2048, 128)\n",
    "        self.linear2 = Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #TODO\n",
    "        #Build the model here:\n",
    "        #Conv1, pooling, dropout, conv2, pooling, flatten, linear1, relu, dropout, linear2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d749f64-08b6-4964-9c78-39dc8e95642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "model.load_state_dict(torch.load('CNN_weights.pth'))\n",
    "model.eval() #Puts the model on 'eval mode', stopping Dropout operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dbd88f-0efd-4b29-bd01-2d8335f282e0",
   "metadata": {},
   "source": [
    "# 2. Loading and Processing Images\n",
    "\n",
    "Images must be converted into pytorch tensors of a specific size for prediction.\n",
    "\n",
    "### Task 2\n",
    "Write a function that converts 'frog.jpg' into a transformed pytorch tensor and resizes it to (32,32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef5e082-0838-483d-b2fd-e7ce47876a3f",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <b>Hint for Task #2</b></summary>\n",
    "\n",
    "In our solution we use \n",
    "```python \n",
    "Compose(Transform1, Transform2)```\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>üîê <b>Solution for Task #2</b></summary>\n",
    "\n",
    "```python\n",
    "\n",
    "def process_image(path):\n",
    "    \"\"\"\n",
    "    Convert file path to scaled torch tensor\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    path : str\n",
    "        Filepath for image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    processedImg: Scaled and transformed image tensor\n",
    "    \n",
    "    \"\"\"\n",
    "    img = Image.open(path)\n",
    "    transform = Compose([Resize((32,32)), ToTensor()])\n",
    "    processedImg = transform(img)\n",
    "    processedImg = processedImg.unsqueeze(0)\n",
    "    return processedImg\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "07415647-c8ce-4a22-b3dc-bf96972127e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from PIL import Image\n",
    "\n",
    "def process_image(path):\n",
    "    \"\"\"\n",
    "    Convert file path to scaled torch tensor\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    path : str\n",
    "        Filepath for image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    processedImg: Scaled and transformed image tensor\n",
    "    \n",
    "    \"\"\"\n",
    "    img = Image.open(path)\n",
    "    ###TODO\n",
    "    #Write a PyTorch image composition to resize and convert to a tensor\n",
    "    transform = None;\n",
    "    ###\n",
    "    processedImg = transform(img)\n",
    "    processedImg = processedImg.unsqueeze(0)\n",
    "    return processedImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721215ac-9837-49bc-90eb-5f925100a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(img):\n",
    "    \"\"\"\n",
    "    Display image tensor using plt\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    img : Tensor\n",
    "        image Tensor to be displayed\n",
    "    \"\"\"\n",
    "    img = img.squeeze(0)\n",
    "    plt.imshow(img.permute(1, 2, 0).detach().numpy()) #Reorder columns as PIL and Torch order image data differently\n",
    "\n",
    "show_image(process_image('frog.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c8bc8-80d2-45b2-a8f2-0818552094a3",
   "metadata": {},
   "source": [
    "## 2a. Making Predictions\n",
    "\n",
    "### Task 2a\n",
    "Using the function you created above, predict what the model classifies the frog to be.\n",
    "\n",
    "If prediction leads to an error, the CNN was likely constructed incorrectly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6fd7de-ce86-48ac-b294-3f0ceeed86e2",
   "metadata": {},
   "source": [
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>üîê <b>Solution for Task #2a</b></summary>\n",
    "\n",
    "```python\n",
    "\n",
    "print(prediction(process_image('frog.jpg')))\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00054fbb-fcc6-4bb6-9191-aecbfce66303",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "def prediction(img):\n",
    "    \"\"\"\n",
    "    Return prediction tuple:\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : PyTorch model used for classification\n",
    "    img : Tensor\n",
    "        image Tensor to be predicted\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pred_class : torch.Tensor\n",
    "        The predicted class label\n",
    "    prob : torch.Tensor\n",
    "        The confidence of the model \n",
    "    \n",
    "    \"\"\"\n",
    "    with torch.no_grad(): #Stops calculating gradients\n",
    "        prediction = model(img)\n",
    "        _, pred_class = torch.max(prediction, 1)\n",
    "    probs = prediction.softmax(dim=-1) #Softmax function used to calculate probabilities\n",
    "    return pred_class, probs[0][pred_class]\n",
    "\n",
    "###TODO\n",
    "#Use the above functions to predict 'frog.jpg'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6c3deec-602c-42a5-8819-4a1a6c13d476",
   "metadata": {},
   "source": [
    "# 3. Making an adversarial image using FGSM\n",
    "$ x' = x + \\epsilon \\cdot sign(\\nabla loss_{F,t}(x))\n",
    "$\n",
    "\n",
    "### Task 3\n",
    "\n",
    "Using the above formula, complete the code for FGSM (Fast Gradient Sign Method). Work out the loss produced by the generated output with regard to the correct output (using loss_fn), and then calculate the gradient of this loss, relative to the input data. Then find the signs of the gradient, and adjust x accordingly.\n",
    "\n",
    "The loss function, CrossEntropyLoss, has also been included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3961158-65aa-42eb-830c-4fdafb6205e6",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <b>Hint for Task #3</b></summary>\n",
    "\n",
    "The following python example demonstrates how to find the gradient of the loss function relative to the image\n",
    "```python\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "x = process_image('frog.jpg')\n",
    "x.requires_grad = True #Turn on gradient calculation\n",
    "output = model(x)\n",
    "loss = loss_fn(output, y) #Find loss \n",
    "loss.backward() #Calculating gradient\n",
    "loss_gradient = x.grad.data\n",
    "x = x.detach() #Turn off gradient calculation\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>üîê <b>Solution for Task #3</b></summary>\n",
    "\n",
    "```python\n",
    "\n",
    "def FGSM_generator(path, y, epsilon=3/1000):\n",
    "    x = process_image(path)\n",
    "    x.requires_grad = True\n",
    "    output = model(x)\n",
    "    loss = loss_fn(output, y)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    loss_gradient = x.grad.data\n",
    "    x = x.detach()\n",
    "    x_dash = x + (epsilon * np.sign(loss_gradient))\n",
    "    x_dash = torch.clamp(x_dash, 0, 1)\n",
    "    return x_dash\n",
    "        \n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5984e408-dd59-46fe-893f-eccc969f3008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def FGSM_generator(model, loss_fn, path, y, epsilon=8/255):\n",
    "    \"\"\"\n",
    "    Create adversarial image with FGSM:\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : PyTorch model used for classification\n",
    "    loss_fn : Loss function\n",
    "    path: Image filepath\n",
    "    y: Image label\n",
    "    epsilon: Perturbation variable\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    adv_img: Adversarially perturbed image tensor\n",
    "    \"\"\"\n",
    "\n",
    "    ### TODO\n",
    "    # Calculate the loss (wrt. output and y)\n",
    "    # Calculate the gradient with respect to input data\n",
    "    # Perturb the image using the signs of the gradient\n",
    "    ###\n",
    "\n",
    "    x_dash = torch.clamp(x_dash, 0, 1)\n",
    "    return x_dash\n",
    "        \n",
    "path = 'frog.jpg'\n",
    "x_adv_FGSM = FGSM_generator(path, prediction(process_image(path))[0])\n",
    "pred = prediction(x_adv_FGSM)\n",
    "print(f\"Prediction: {classes[pred[0]]} with probability {pred[1][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887e7518-2b1f-4990-b2ae-850d93df545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(x_adv_FGSM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ee09ed9-587c-4765-8528-4b6ad81f60f0",
   "metadata": {},
   "source": [
    "# 4. Making an adversarial image using IGSM \n",
    "\n",
    "\n",
    "### Task 4\n",
    "First, complete the helper function for clipping. All this operation has to do is force x to be between x - Œµ and x + Œµ, and between 0 and 1. The clamp function can be used for this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736aa33f-d2d8-49ff-90cc-f85e18b05d89",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üîê <b>Solution for Task #4</b></summary>\n",
    "\n",
    "```python\n",
    "\n",
    "def clip(x, epsilon):\n",
    "    \"\"\"\n",
    "    Return clipped x\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x: Input image tensor\n",
    "    epsilon: Perturbation variable\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    x_clipped: Clipped version of image tensor x\n",
    "    \"\"\"\n",
    "    x = torch.clamp(x, x - epsilon, x + epsilon)\n",
    "    x = torch.clamp(x, 0, 1)\n",
    "    return x\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31087c18-88d8-49fe-9cbb-978c3fead782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import clamp\n",
    "\n",
    "def clip(x, epsilon):\n",
    "    \"\"\"\n",
    "    Return clipped x\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x: Input image tensor\n",
    "    epsilon: Perturbation variable\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    x_clipped: Clipped version of image tensor x\n",
    "    \"\"\"\n",
    "    ### TODO\n",
    "    #Clip x epsilon distance away\n",
    "    #Clip x between 0 and 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a45e60e-982c-44d0-b07d-78ff2fd1f590",
   "metadata": {},
   "source": [
    "### Task 4a\n",
    "\n",
    "$ x'_i = x'_{i-1} + clip_\\epsilon(\\alpha \\cdot sign(\\nabla loss_{F,t}(x'_{i-1})))\n",
    "$\n",
    "\n",
    "Using the above formula, complete the code for IGSM (Iterative Gradient Sign Method). You will not have to change much from your existing code for FGSM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d66c80-5304-42a7-a65e-367c882297c7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üîê <b>Solution for Task #4a</b></summary>\n",
    "\n",
    "```python\n",
    "\n",
    "def IGSM_generator(path, y, epsilon=1/1000, alpha=0.0005, num_iters=6):\n",
    "    \"\"\"\n",
    "    Create adversarial image with IGSM:\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : PyTorch model used for classification\n",
    "    loss_fn : Loss function\n",
    "    path: Image filepath\n",
    "    y: Image label\n",
    "    epsilon: Perturbation variable\n",
    "    Alpha: Perturbation variable\n",
    "    num_iters: Number of iterations\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    adv_img: Adversarially perturbed image tensor\n",
    "    \"\"\"\n",
    "    x = process_image(path)\n",
    "    x.requires_grad = True\n",
    "    for i in range(num_iters):\n",
    "        x.requires_grad = True\n",
    "        output = model(x)\n",
    "        loss = loss_fn(output, y)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        loss_gradient = x.grad.data\n",
    "        x = x.detach()\n",
    "        x = x + alpha * torch.sign(loss_gradient)\n",
    "        x = clip(x, epsilon)    \n",
    "    return x\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971994f4-3ef0-42f5-812e-2dc03e57a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IGSM_generator(model, loss_fn, path, y, epsilon=1/1000, alpha=0.0005, num_iters=6):\n",
    "    \"\"\"\n",
    "    Create adversarial image with IGSM:\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : PyTorch model used for classification\n",
    "    loss_fn : Loss function\n",
    "    path: Image filepath\n",
    "    y: Image label\n",
    "    epsilon: Perturbation variable\n",
    "    Alpha: Perturbation variable\n",
    "    num_iters: Number of iterations\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    adv_img: Adversarially perturbed image tensor\n",
    "    \"\"\"\n",
    "    ### TODO\n",
    "    #Implement IGSM using your code for FGSM\n",
    "    ###\n",
    "\n",
    "    return None\n",
    "    \n",
    "path = 'frog.jpg'\n",
    "x_adv_IGSM = IGSM_generator(path, prediction(process_image(path))[0])\n",
    "pred = prediction(x_adv_IGSM)\n",
    "print(f\"Prediction: {classes[pred[0]]} with probability {pred[1][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d2be6b-702d-4455-8b5b-79c62d5382d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(x_adv_IGSM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e657cc9-af35-4e34-a151-e7748ad850f3",
   "metadata": {},
   "source": [
    "# 5. Making an adversarial image using PGD\n",
    "\n",
    "PGD is almost identical to IGSM, with the only difference being 'random' intialization rather than zero.\n",
    "\n",
    "### Task 5\n",
    "Implement PGD. A helper function has been included to help do this. The 'clip' function you made above is also necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bbf12e-39b6-4b8d-914c-dc82042be5df",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üîê <b>Solution for Task #5</b></summary>\n",
    "\n",
    "```python\n",
    "\n",
    "def PGD_generator(path, y, epsilon=1/1000, alpha=0.0005, num_iters=6):\n",
    "    \"\"\"\n",
    "    Return prediction tuple:\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : PyTorch model used for classification\n",
    "    loss_fn : Loss function\n",
    "    path: Image filepath\n",
    "    y: Image label\n",
    "    epsilon: Perturbation variable\n",
    "    Alpha: Perturbation variable\n",
    "    num_iters: Number of iterations\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    adv_img: Adversarially perturbed image tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    x = process_image(path)\n",
    "    x = add_noise(x)\n",
    "    x = torch.clamp(x, -1, 1)\n",
    "    for i in range(num_iters):\n",
    "        x.requires_grad = True\n",
    "        output = model(x)\n",
    "        loss = loss_fn(output, y)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        loss_gradient = x.grad.data\n",
    "        x = x.detach()\n",
    "        x = x + alpha * torch.sign(loss_gradient)\n",
    "        x = clip(x, epsilon)\n",
    "    return x\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef17eee-9954-49dd-a78b-750916fa60fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(img, stdev=0.001, mean=0):\n",
    "    \"\"\"\n",
    "    Helper function for PGD_generator\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    img : Tensor\n",
    "        image Tensor to be predicted\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    noisy_img: Tensor\n",
    "        Added noise to input\n",
    "    \"\"\"\n",
    "    noise = torch.randn_like(img) * stdev + mean\n",
    "    return img + noise\n",
    "\n",
    "def PGD_generator(model, loss_fn, path, y, epsilon=1/1000, alpha=0.0005, num_iters=6):\n",
    "    \"\"\"\n",
    "    Create adversarial image with PGD:\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : PyTorch model used for classification\n",
    "    loss_fn : Loss function\n",
    "    path: Image filepath\n",
    "    y: Image label\n",
    "    epsilon: Perturbation variable\n",
    "    Alpha: Perturbation variable\n",
    "    num_iters: Number of iterations\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    adv_img: Adversarially perturbed image tensor\n",
    "    \"\"\"\n",
    "\n",
    "    ###TODO\n",
    "    # Implement PGD using your code for IGSM and the add_noise function\n",
    "    ###\n",
    "\n",
    "    return None\n",
    "\n",
    "path = 'frog.jpg'\n",
    "x_adv_PGD = PGD_generator(model, loss_fn, path, prediction(process_image(path))[0])\n",
    "pred = prediction(x_adv_PGD)\n",
    "print(f\"Prediction: {classes[pred[0]]} with probability {pred[1][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce9e72d-8ea7-46c8-9511-02a280b535c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(x_adv_PGD)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "810e4e02-9139-4928-8f8e-80fb6be2752c",
   "metadata": {},
   "source": [
    "# 6. Evaluating the distance\n",
    "\n",
    "\n",
    "Now, we will evaluate the distance between the original image and the adversarial images.\n",
    "\n",
    "### Task 6\n",
    "Implement the below formula:\n",
    "\n",
    "$\n",
    "\\|v\\|_p = \\left( \\sum_{i=1}^{n} |v_i|^p \\right)^{\\frac{1}{p}}.\n",
    "$\n",
    "\n",
    "\n",
    "Where v is the absolute difference between the input image and the adversarially perturbed image, complete the following function. This is equivalent to calculating the L_p norm.\n",
    "\n",
    "Due to the addition of random noise, the distance for PGD will fluctuate above and below that of IGSM if they have the same parameters.\n",
    "\n",
    "While numerical stability might render it impossible, the L_p norm should converge to the L_inf norm as p goes to infinity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac835d3-962f-4f67-838a-daf8026d7373",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üîê <b>Solution for Task #6</b></summary>\n",
    "\n",
    "```python\n",
    "\n",
    "def distance(x1, x2, p):\n",
    "    \"\"\"\n",
    "    Return p norm of x1 and x2\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x1: Input tensor\n",
    "    x2: Input tensor\n",
    "    p: Norm integer\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    distance: p norm of x1 and x2\n",
    "    \"\"\"\n",
    "    x = (torch.abs(x1 - x2)) ** p\n",
    "    x = torch.sum(x)\n",
    "    return x ** (1/p)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c6e62ea1-a68a-46a6-9976-980d7782550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1, x2, p):\n",
    "    \"\"\"\n",
    "    Return p norm of x1 and x2\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x1: Input tensor\n",
    "    x2: Input tensor\n",
    "    p: Norm integer\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    distance: p norm of x1 and x2\n",
    "    \"\"\"\n",
    "    ### TODO\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea31a90-790d-43a5-bad7-1ed256cdc720",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = process_image('frog.jpg')\n",
    "print(f\"Distance for FGSM: {distance(x, x_adv_FGSM, 2):.2f}\")\n",
    "print(f\"Distance for IGSM: {distance(x, x_adv_IGSM, 2):.2f}\")\n",
    "print(f\"Distance for PGD: {distance(x, x_adv_PGD, 2):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08403b13-dbd1-4bcb-bc32-e032e8c5bd1a",
   "metadata": {},
   "source": [
    "# 6a. Numerical Stability\n",
    "\n",
    "Unfortunately, this approach lacks numerical stability as p goes to infinity. To mitigate this, the distance function can be tweaked slightly to allow for a more precise calculation. \n",
    "\n",
    "For example, the below example goes to 0 instead of the L_inf norm of 0.0069."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d71bc81-9160-476c-be4b-fcdadf7d3120",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distance(x, x_adv_IGSM, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e406441-2e7b-4236-849c-7b0cf11b5712",
   "metadata": {},
   "source": [
    "Here is more numerically stable version of the function. It divides the difference tensor by its maximimum value before raising it to the power of p, before multiplying it back again, leading to greater robustness. Intuitively, this is because it makes every value lower than one, so there is no explosion with increasing powers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3ef6b9-5570-46ef-841e-83870acaa70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1, x2, p):\n",
    "    \"\"\"\n",
    "    Return p norm of x1 and x2\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x1: Input tensor\n",
    "    x2: Input tensor\n",
    "    p: Norm integer\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    distance: p norm of x1 and x2\n",
    "    \"\"\"\n",
    "    z = torch.max(abs(x1 - x2))\n",
    "    x = (torch.abs(x1 - x2) / z) ** p\n",
    "    x = torch.sum(x)\n",
    "    return z * x ** (1/p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b49af81-aec4-490b-90b3-fbf4e43ab8a4",
   "metadata": {},
   "source": [
    "The below demonstration shows how the L_norm of x and PGD converges to L_inf as p goes to infinity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c04635e-6fd6-4124-bda5-835347a64950",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_inf_norm = torch.max(torch.abs(x - x_adv_PGD)).item()\n",
    "p_values = range(3,50)  \n",
    "distances = [distance(x, x_adv_PGD, p).item() for p in p_values]\n",
    "\n",
    "plt.plot(p_values, distances, 'b-', linewidth=2, markersize=6)\n",
    "plt.axhline(y=l_inf_norm, color='r', linestyle='--', label=f'L-‚àû norm: {l_inf_norm:.4f}')\n",
    "plt.xlabel('p value', fontsize=12)\n",
    "plt.ylabel('Distance', fontsize=12)\n",
    "plt.title('Convergence of Lp Distance to L-‚àû Norm as p Increases', fontsize=14)\n",
    "plt.grid(True, ls=\"--\", alpha=0.7)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
