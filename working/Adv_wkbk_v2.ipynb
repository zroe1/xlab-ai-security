{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b32503e-255a-4191-9fc2-b7bfa65874f4",
   "metadata": {},
   "source": [
    "# Introduction to Adversarial Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b6a1ba-a70f-4246-8d8a-6826bb6997ee",
   "metadata": {},
   "source": [
    "# 1. Loading a CNN\n",
    "To save time, we will use a pretrained CNN (on the CIFAR-10 dataset) in order to test various adversarial methods. It has a straight-forward architecture, which is shown below. To save having to store the model architecture as a file, only the weights can be stored, and the model architecture can be replicated as follows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03a9ff1-762c-454b-a0bb-4a0513952fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, ReLU, Dropout #All of the necessary layers for this model\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = Conv2d(3, 16, kernel_size = 3, padding = 1)\n",
    "        self.pooling = MaxPool2d(2,2)\n",
    "        self.dropout = Dropout(p=0.3)\n",
    "        self.conv2 = Conv2d(16, 32, kernel_size = 3, padding = 1)\n",
    "        self.relu = ReLU()\n",
    "        self.flatten = Flatten()\n",
    "        self.linear1 = Linear(2048, 128)\n",
    "        self.linear2 = Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #TODO\n",
    "        #Build the model here:\n",
    "        #Conv1, pooling, dropout, conv2, pooling, flatten, linear1, relu, dropout, linear2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d749f64-08b6-4964-9c78-39dc8e95642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "model.load_state_dict(torch.load('CNN_weights.pth'))\n",
    "model.eval() #Puts the model on 'eval mode', stopping Dropout operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dbd88f-0efd-4b29-bd01-2d8335f282e0",
   "metadata": {},
   "source": [
    "# 2. Loading and Processing Images\n",
    "\n",
    "Images must be converted into pytorch tensors of a specific size for prediction.\n",
    "\n",
    "Write a function that converts 'frog.jpg' into a transformed pytorch tensor and resizes it to (32,32)\n",
    "\n",
    "Hint: use Compose([Transform1(), Transform2()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07415647-c8ce-4a22-b3dc-bf96972127e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from PIL import Image\n",
    "\n",
    "def process_image(path):\n",
    "    img = Image.open(path)\n",
    "    ###TODO\n",
    "    #Write a PyTorch image composition to resize and convert to a tensor\n",
    "    transform = None;\n",
    "    ###\n",
    "    processedImg = transform(img)\n",
    "    processedImg = processedImg.unsqueeze(0)\n",
    "    return processedImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721215ac-9837-49bc-90eb-5f925100a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(img):\n",
    "    img = img.squeeze(0)\n",
    "    plt.imshow(img.permute(1, 2, 0).detach().numpy()) #Reorder columns as PIL and Torch order image data differently\n",
    "\n",
    "show_image(process_image('frog.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c8bc8-80d2-45b2-a8f2-0818552094a3",
   "metadata": {},
   "source": [
    "## 2a. Making Predictions\n",
    "Using the function you created above, predict what the model classifies the frog to be.\n",
    "\n",
    "If prediction leads to an error, the CNN was likely constructed incorrectly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00054fbb-fcc6-4bb6-9191-aecbfce66303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(img):\n",
    "    classes = ['plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    with torch.no_grad(): #Stops calculating gradients\n",
    "        prediction = model(img)\n",
    "        _, pred_class = torch.max(prediction, 1)\n",
    "    probs = prediction.softmax(dim=-1) #Softmax function used to calculate probabilities\n",
    "    return pred_class, classes[pred_class], probs[0][pred_class]\n",
    "\n",
    "###TODO\n",
    "#Use the above functions to predict 'frog.jpg'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6c3deec-602c-42a5-8819-4a1a6c13d476",
   "metadata": {},
   "source": [
    "# 3. Making an adversarial image using FGSM\n",
    "$ x' = x + \\epsilon \\cdot sign(\\nabla loss_{F,t}(x))\n",
    "$\n",
    "\n",
    "Using the above formula, complete the code for FGSM (Fast Gradient Sign Method). Work out the loss produced by the generated output with regard to the correct output (using loss_fn), and then calculate the gradient of this loss, relative to the input data. Then find the signs of the gradient, and adjust x accordingly.\n",
    "\n",
    "The loss function, CrossEntropyLoss, has also been included.\n",
    "\n",
    "The below example demonstrates how to find the gradient of the loss function relative to the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd172bb-c290-474a-8e7a-5951e9280569",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "x = process_image('frog.jpg')\n",
    "x.requires_grad = True #Turn on gradient calculation\n",
    "output = model(x)\n",
    "loss = loss_fn(output, y) #Find loss \n",
    "loss.backward() #Calculating gradient\n",
    "loss_gradient = x.grad.data\n",
    "x = x.detach() #Turn off gradient calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5984e408-dd59-46fe-893f-eccc969f3008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def FGSM_generator(path, y, epsilon=8/255):\n",
    "\n",
    "    ### TODO\n",
    "    # Calculate the loss (wrt. output and y)\n",
    "    # Calculate the gradient with respect to input data\n",
    "    # Perturb the image using the signs of the gradient\n",
    "    ###\n",
    "\n",
    "    x_dash = torch.clamp(x_dash, 0, 1)\n",
    "    return x_dash\n",
    "        \n",
    "path = 'frog.jpg'\n",
    "x_adv_FGSM = FGSM_generator(path, prediction(process_image(path))[0])\n",
    "pred = prediction(x_adv_FGSM)\n",
    "print(f\"Prediction: {pred[1]} with probability {pred[2][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887e7518-2b1f-4990-b2ae-850d93df545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(x_adv_FGSM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ee09ed9-587c-4765-8528-4b6ad81f60f0",
   "metadata": {},
   "source": [
    "# 4. Making an adversarial image using IGSM \n",
    "$ x'_i = x'_{i-1} + clip_\\epsilon(\\alpha \\cdot sign(\\nabla loss_{F,t}(x'_{i-1})))\n",
    "$\n",
    "\n",
    "Using the above formula, complete the code for IGSM (Iterative Gradient Sign Method)\n",
    "\n",
    "Before, complete the helper function for clipping. All this operation has to do is force x to be between x - ε and x + ε, and between 0 and 1. The clamp function can be used for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31087c18-88d8-49fe-9cbb-978c3fead782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import clamp\n",
    "\n",
    "def clip(x, epsilon):\n",
    "    ### TODO\n",
    "    #Clip x epsilon distance away\n",
    "    #Clip x between 0 and 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971994f4-3ef0-42f5-812e-2dc03e57a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IGSM_generator(path, y, epsilon=1/1000, alpha=0.0005, num_iters=6):\n",
    "    \n",
    "    ### TODO\n",
    "    #Implement IGSM using your code for FGSM\n",
    "    ###\n",
    "\n",
    "    return None\n",
    "    \n",
    "path = 'frog.jpg'\n",
    "x_adv_IGSM = IGSM_generator(path, prediction(process_image(path))[0])\n",
    "pred = prediction(x_adv_IGSM)\n",
    "print(f\"Prediction: {pred[1]} with probability {pred[2][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d2be6b-702d-4455-8b5b-79c62d5382d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(x_adv_IGSM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e657cc9-af35-4e34-a151-e7748ad850f3",
   "metadata": {},
   "source": [
    "# 5. Making an adversarial image using PGD\n",
    "\n",
    "PGD is almost identical to IGSM, with the only difference being 'random' intialization rather than zero.\n",
    "\n",
    "A helper function has been included to help do this. The 'clip' function included above is also necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef17eee-9954-49dd-a78b-750916fa60fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(img, stdev=0.001, mean=0):\n",
    "    noise = torch.randn_like(img) * stdev + mean\n",
    "    return img + noise\n",
    "\n",
    "def PGD_generator(path, y, epsilon=1/1000, alpha=0.0005, num_iters=6):\n",
    "\n",
    "    ###TODO\n",
    "    # Implement PGD using your code for IGSM and the add_noise function\n",
    "    ###\n",
    "\n",
    "    return None\n",
    "\n",
    "path = 'frog.jpg'\n",
    "x_adv_PGD = PGD_generator(path, prediction(process_image(path))[0])\n",
    "pred = prediction(x_adv_PGD)\n",
    "print(f\"Prediction: {pred[1]} with probability {pred[2][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce9e72d-8ea7-46c8-9511-02a280b535c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(x_adv_PGD)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "810e4e02-9139-4928-8f8e-80fb6be2752c",
   "metadata": {},
   "source": [
    "# 6. Evaluating the distance\n",
    "\n",
    "\n",
    "Now, we will evaluate the distance between the original image and the adversarial images.\n",
    "\n",
    "Using the below formula:\n",
    "\n",
    "$\n",
    "\\|v\\|_p = \\left( \\sum_{i=1}^{n} |v_i|^p \\right)^{\\frac{1}{p}}.\n",
    "$\n",
    "\n",
    "Where v is the absolute difference between the input image and the adversarially perturbed image, complete the following function. This is equivalent to calculating the L_p norm.\n",
    "\n",
    "Due to the addition of random noise, the distance for PGD will fluctuate above and below that of IGSM if they have the same parameters.\n",
    "\n",
    "While numerical stability might render it impossible, the L_p norm should converge to the L_inf norm as p goes to infinity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e62ea1-a68a-46a6-9976-980d7782550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1, x2, p):\n",
    "    ### TODO\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea31a90-790d-43a5-bad7-1ed256cdc720",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = process_image('frog.jpg')\n",
    "print(f\"Distance for FGSM: {distance(x, x_adv_FGSM, 2):.2f}\")\n",
    "print(f\"Distance for IGSM: {distance(x, x_adv_IGSM, 2):.2f}\")\n",
    "print(f\"Distance for PGD: {distance(x, x_adv_PGD, 2):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08403b13-dbd1-4bcb-bc32-e032e8c5bd1a",
   "metadata": {},
   "source": [
    "# 6a. Numerical Stability\n",
    "\n",
    "Unfortunately, this approach lacks numerical stability as p goes to infinity. To mitigate this, the distance function can be tweaked slightly to allow for a more precise calculation. \n",
    "\n",
    "For example, the below example goes to 0 instead of the L_inf norm of 0.0069."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d71bc81-9160-476c-be4b-fcdadf7d3120",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distance(x, x_adv_IGSM, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e406441-2e7b-4236-849c-7b0cf11b5712",
   "metadata": {},
   "source": [
    "Here is more numerically stable version of the function. It divides the difference tensor by its maximimum value before raising it to the power of p, before multiplying it back, leading to greater robustness. Intuitively, this is because it makes every value lower than one, so there is no explosion with increasing powers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3ef6b9-5570-46ef-841e-83870acaa70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1, x2, p):\n",
    "    z = torch.max(abs(x1 - x2))\n",
    "    x = (torch.abs(x1 - x2) / z) ** p\n",
    "    x = torch.sum(x)\n",
    "    return z * x ** (1/p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b49af81-aec4-490b-90b3-fbf4e43ab8a4",
   "metadata": {},
   "source": [
    "The below demonstration shows how the L_norm of x and PGD converges to L_inf as p goes to infinity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c04635e-6fd6-4124-bda5-835347a64950",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_inf_norm = torch.max(torch.abs(x - x_adv_PGD)).item()\n",
    "p_values = range(3,50)  \n",
    "distances = [distance(x, x_adv_PGD, p).item() for p in p_values]\n",
    "\n",
    "plt.plot(p_values, distances, 'b-', linewidth=2, markersize=6)\n",
    "plt.axhline(y=l_inf_norm, color='r', linestyle='--', label=f'L-∞ norm: {l_inf_norm:.4f}')\n",
    "\n",
    "plt.xlabel('p value', fontsize=12)\n",
    "plt.ylabel('Distance', fontsize=12)\n",
    "plt.title('Convergence of Lp Distance to L-∞ Norm as p Increases', fontsize=14)\n",
    "plt.grid(True, ls=\"--\", alpha=0.7)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
