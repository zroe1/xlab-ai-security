{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e828500-86e7-4eab-9f3d-8ebc5d4015cc",
   "metadata": {},
   "source": [
    "## Square Attack\n",
    "\n",
    "The Square Attack is a black-box method used to generate adversarial samples. Unlike 'white-box' approachs such as PGD or FGSM, the Square Attack does not require knowing model weights or gradients. \n",
    "\n",
    "While other black-box attack take many queries to perform attacks the square attack makes relatively few.  The attack works by taking repeated alterations in the shape of a square on the image, keeping it if it increases the loss of the model. The Square Attack, upon release, was successful enough that it even outperformed some existing white-box approaches on benchmarks.s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db55a50-6b0f-483e-a5ed-163ac93045a4",
   "metadata": {},
   "source": [
    "## 1. Loading and Processing Models and Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da62955b-5230-4b11-a53d-b55a12874b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF YOU ARE IN COLAB OR HAVE NOT INSTALLED `xlab-security`\n",
    "!pip install xlab-security # should not take more than a minute or two to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38fde14-a5dd-4abd-9d86-ff003d14cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlab\n",
    "from xlab.utils import prediction, process_image, show_image, CIFAR10\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from huggingface_hub import hf_hub_download\n",
    "from xlab.models import MiniWideResNet, BasicBlock\n",
    "import torch\n",
    "\n",
    "classes = CIFAR10().classes\n",
    "IMG_PATH = 'car.jpg'\n",
    "\n",
    "model = MiniWideResNet()\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=\"uchicago-xlab-ai-security/tiny-wideresnet-cifar10\",\n",
    "    filename=\"adversarial_basics_cnn.pth\"\n",
    ")\n",
    "\n",
    "model = torch.load(model_path, map_location='cpu', weights_only = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23201df4-b1c2-4f88-b216-93cda89c0319",
   "metadata": {},
   "source": [
    "## 2. The $ L_\\infty $ Attack\n",
    "\n",
    "### Task 1\n",
    "First, we will start by making a helper function for the $ L_\\infty $ attack. This will be the function for creating the distribution used to alter squares. In this algorithm, two corner indices $ r, s $ are randomly sampled, and are used with the window size $ h $ to create a window, which is then altered. The perturbation $ p $, used to alter the pixels in the window, is randomly sampled between $ -2\\epsilon $ and $ 2\\epsilon $. Each colour channel is altered separately, with the same window being changed in each.\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "\\text{\\bf Algorithm 2: Sampling distribution } P \\text{ for } l_\\infty\\text{-norm} \\\\\n",
    "\\hline\n",
    "\\text{\\bf Input: } \\text{maximal norm } \\epsilon, \\text{ window size } h, \\text{ image size } w, \\text{ color channels } c \\\\\n",
    "\\text{\\bf Output: } \\text{New update } \\delta \\\\[0.5em]\n",
    "\\delta \\leftarrow \\text{array of zeros of size } w \\times w \\times c \\\\\n",
    "\\text{sample uniformly } r, s \\in \\{0, \\dots, w - h\\} \\subset \\mathbb{N} \\\\\n",
    "\\text{\\bf for } i = 1, \\dots, c \\text{ \\bf do } \\\\\n",
    "\\quad \\rho \\leftarrow \\text{Uniform}(\\{-2\\epsilon, 2\\epsilon\\}) \\\\\n",
    "\\quad \\delta_{r+1:r+h, \\: s+1:s+h, \\: i} \\leftarrow \\rho \\cdot \\mathbf{1}_{h \\times h} \\\\\n",
    "\\text{\\bf end } \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b5a1eb-870e-4d7e-b9d5-cc062a5c2836",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <b>Hint for Task #1</b></summary>\n",
    "\n",
    "In our solution we use ```torch.zeros``` to create a null matrix of the right shape and then add the individual values.\n",
    "\n",
    "</details>\n",
    "<details>\n",
    "<summary>üí° <b>Hint for Task #1</b></summary>\n",
    "\n",
    "In our solution, we index for the window using:\n",
    "```arr[a:b+c][d:e+f]```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>üîê <b>Solution for Task #1</b></summary>\n",
    "\n",
    "```python\n",
    "def l_inf_dist(epsilon, h, w, c):\n",
    "    \"\"\"Generates a sparse adversarial perturbation by adding uniform noise to a random square patch\n",
    "    \n",
    "    Args:\n",
    "        epsilon (float): Maximum perturbation magnitude.\n",
    "        h (int): Height and width of the square patch to perturb.\n",
    "        w (int): Height and width of the full image.\n",
    "        c (int): Number of color channels.\n",
    "        \n",
    "    Returns:\n",
    "        [c, w, w]: Sparse perturbation tensor with random noise in a single square patch.\n",
    "    \"\"\"\n",
    "    randy = torch.randint(0, w- h, (1,)) \n",
    "    randx = torch.randint(0, w- h, (1,)) \n",
    "\n",
    "    ps = (torch.rand(c,1,1) - 0.5) * 4 * epsilon\n",
    "    delta = torch.zeros(c, w, w)\n",
    "    delta[:,randy:randy+h, randx:randx+h] = ps\n",
    "\n",
    "    return delta\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1327245-a6ab-4e49-8cf1-2ad6a426baba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_inf_dist(epsilon, h, w, c):\n",
    "    \"\"\"Generates a sparse adversarial perturbation by adding uniform noise to a random square patch\n",
    "    \n",
    "    Args:\n",
    "        epsilon (float): Maximum perturbation magnitude.\n",
    "        h (int): Height and width of the square patch to perturb.\n",
    "        w (int): Height and width of the full image.\n",
    "        c (int): Number of color channels.\n",
    "        \n",
    "    Returns:\n",
    "        [c, w, w]: Sparse perturbation tensor with random noise in a single square patch.\n",
    "    \"\"\"\n",
    "    randy = torch.randint(0, w- h, (1,)) \n",
    "    randx = torch.randint(0, w- h, (1,)) \n",
    "\n",
    "    ps = (torch.rand(c,1,1) - 0.5) * 4 * epsilon\n",
    "    delta = torch.zeros(c, w, w)\n",
    "    delta[:,randy:randy+h, randx:randx+h] = ps\n",
    "\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b478ac0-0ea0-4bc8-871a-bd5016ba75ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = l_inf_dist(0.1, 5, 50, 3)\n",
    "_ = xlab.utils.plot_tensors([\n",
    "        delta[0],\n",
    "        delta[1],\n",
    "        delta[2]\n",
    "    ],\n",
    "    ncols=3,\n",
    "    titles=[\"red channel\", \"green channel\", \"blue channel\"] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d3c4e9-96d5-4a49-8cc4-49a3520f3a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = xlab.tests.square.task1(l_inf_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e092a19c-393f-4658-be50-4ae1d528ad49",
   "metadata": {},
   "source": [
    "## 2.1 The Square Attack loop.\n",
    "### Task 2\n",
    "Now, we will use the distribution within the main loop of the  $ L_\\infty $ attack. Similar code will be used to run the $ L_2 $ attack. Intuitively, this algorithm involves choosing a window size $ h $ using a schedule of sorts, and then altering the image using the above helper function, until the image is adversarial or a particular number of iterations is reached.\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "\\text{\\bf Algorithm: Projected Gradient-Free Adversarial Attack} \\\\\n",
    "\\hline\n",
    "\\text{\\bf Input: } \\text{classifier } f, \\text{ point } x \\in \\mathbb{R}^d, \\text{ image size } w, \\text{ number of color channels } c, \\\\\n",
    "\\quad l_p\\text{-radius } \\epsilon, \\text{ label } y \\in \\{1, \\dots, K\\}, \\text{ number of iterations } N \\\\\n",
    "\\text{\\bf Output: } \\text{approximate minimizer } \\hat{x} \\in \\mathbb{R}^d \\text{ of the problem stated in Eq. (1)} \\\\[0.5em]\n",
    "\\hat{x} \\leftarrow \\text{init}(x) \\\\ \n",
    "l^* \\leftarrow L(f(x), y) \\\\\n",
    "i \\leftarrow 1 \\\\\n",
    "\\text{\\bf while } i < N \\text{ and } \\hat{x} \\text{ is not adversarial \\bf do} \\\\\n",
    "\\quad h^{(i)} \\leftarrow \\text{side length of the square to modify (according to some schedule)} \\\\\n",
    "\\quad \\delta \\sim P(\\epsilon, h^{(i)}, w, c, \\hat{x}, x) \\\\\n",
    "\\quad \\hat{x}_{\\text{new}} \\leftarrow \\text{Project } \\hat{x} + \\delta \\text{ onto } \\{z \\in \\mathbb{R}^d : \\|z - x\\|_p \\le \\epsilon\\} \\cap [0, 1]^d \\\\\n",
    "\\quad l_{\\text{new}} \\leftarrow L(f(\\hat{x}_{\\text{new}}), y) \\\\\n",
    "\\quad \\text{\\bf if } l_{\\text{new}} < l^* \\text{ \\bf then } \\hat{x} \\leftarrow \\hat{x}_{\\text{new}}, l^* \\leftarrow l_{\\text{new}} \\\\\n",
    "\\quad i \\leftarrow i + 1 \\\\\n",
    "\\text{\\bf end } \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b8d66a-e24f-4b1c-86f2-39c6f3cc4732",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <b>Hint for Task #2</b></summary>\n",
    "\n",
    "In our solution, we use the div operator, ```//``` for the floor function.\n",
    "</details>\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>üîê <b>Solution for Task #2</b></summary>\n",
    "\n",
    "```python\n",
    "def l_inf_square_attack(model, loss_fn, x, y, N, w=32, c=3, epsilon=15/1000, max_h = 6):\n",
    "    \"\"\"Generates adversarial example using iterative square patch perturbations with L-infinity constraints\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network model with forward() method.\n",
    "        loss_fn: Loss function for optimization.\n",
    "        x [c, w, w]: Input image tensor.\n",
    "        y (int): True class label.\n",
    "        N (int): Maximum number of optimization iterations.\n",
    "        w (int): Image width and height.\n",
    "        c (int): Number of color channels.\n",
    "        epsilon (float): Maximum perturbation magnitude per pixel.\n",
    "        max_h (int): Initial square patch size, gradually reduced during optimization.\n",
    "    \n",
    "    Returns:\n",
    "        [c, w, w]: Adversarial image tensor with successful misclassification or best attempt.\n",
    "    \"\"\"\n",
    "    x_hat = x\n",
    "    loss = loss_fn(model(x), y)\n",
    "    i = 1\n",
    "    h = max_h\n",
    "    while i < N and prediction(model, x_hat)[0] == y:\n",
    "        if i % (N // max_h) == 0:\n",
    "            if h > 2:\n",
    "                h -= 1\n",
    "        delta = l_inf_dist(h=h, epsilon=epsilon, w=w, c=c)\n",
    "        x_new = x_hat + delta\n",
    "        x_new = torch.clamp(x_new, 0, 1)\n",
    "        loss_new = loss_fn(model(x_new), y)\n",
    "        if loss_new > loss:\n",
    "            loss = loss_new\n",
    "            x_hat = x_new \n",
    "        i += 1\n",
    "    return x_hat\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f331d120-16d4-4d32-b793-94db85fa5030",
   "metadata": {},
   "source": [
    "A basic schedule could involve reducing h by one (from max_h) every N//h iterations until the value of 2 is reached. This reduces the size of the window over time, reducing the scale of the perturbations, simulating a sort of convergence onto an adversarial image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af85271-4335-4282-b29b-eeb1e946681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_inf_square_attack(model, loss_fn, x, y, N, w=32, c=3, epsilon=15/1000, max_h = 6):\n",
    "    \"\"\"Generates adversarial example using iterative square patch perturbations with L-infinity constraints\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network model with forward() method.\n",
    "        loss_fn: Loss function for optimization.\n",
    "        x [c, w, w]: Input image tensor.\n",
    "        y (int): True class label.\n",
    "        N (int): Maximum number of optimization iterations.\n",
    "        w (int): Image width and height.\n",
    "        c (int): Number of color channels.\n",
    "        epsilon (float): Maximum perturbation magnitude per pixel.\n",
    "        max_h (int): Initial square patch size, gradually reduced during optimization.\n",
    "    \n",
    "    Returns:\n",
    "        [c, w, w]: Adversarial image tensor with successful misclassification or best attempt.\n",
    "    \"\"\"\n",
    "\n",
    "    raise NotImplementedError(\"l_inf_square_attack hasn't been implemented.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb849286-56d7-42cd-9ad4-e33d42744fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = xlab.tests.square.task2(model, l_inf_square_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816b6275-76e2-4f12-a29a-c9ae9100f66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = process_image(IMG_PATH)\n",
    "label = prediction(model, process_image(IMG_PATH))[0]\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "x_adv = l_inf_square_attack(model, loss_fn, img, label, 500)\n",
    "pred = prediction(model, x_adv)\n",
    "print(f\"{classes[pred[0]]} with probability {pred[1][0]:.4f}\")\n",
    "show_image(x_adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182b012d-c9ab-4b28-bc57-5d4678549ff1",
   "metadata": {},
   "source": [
    "## 3. The $ L_2 $ Attack\n",
    "While the main loop of this attack is the same as the above, the distribution is entirely different. We will begin by producing the helper functions for this, and then the function itself. As the name suggests, the $L_2$ attack minimizes the $L_2$ difference between the original image and the perturbed one, so it is inherently slower and more complex. \n",
    "\n",
    "The $L_2$ distribution creates two adjacent rectangles of pixels (forming a square). The pixels in each rectangle have opposite signs. Placed together, this has a successfully adversarial effect. We will first create some helper functions for this, before moving on to implementing the distribution itself. This is significantly harder to implement than the $L_\\infty$ attack, and has been included as more of an implementation challenge than anything. This section can be skipped through if found too challenging, but it is a good way to test your skills and practice using torch functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf4b362-7364-4457-8ba0-b1f5487411d9",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "Code the $M$ helper function for $L_2$ distribution. This function effectively creates a 'pyramidal' shape of values, with the highest value in the centre, and decreasing values radially around it. This is used to create adversarial perturbations‚Äîexperiments show it to be an effective method.\n",
    "$$\n",
    "M(r, s) = \\left\\lfloor \\frac{h_1}{2} \\right\\rfloor - \n",
    "\\max\\left\\{\n",
    "    \\left| r - \\left\\lfloor \\frac{h_1}{2} \\right\\rfloor - 1 \\right|, \n",
    "    \\left| s - \\left\\lfloor \\frac{h_2}{2} \\right\\rfloor - 1 \\right|\n",
    "\\right\\}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dc8f83-8a4e-4359-815c-94ecd4c7f6c9",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <b>Hint for Task #3</b></summary>\n",
    "\n",
    "In our solution, we use the div operator, ```//``` for the floor function.\n",
    "</details>\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>üîê <b>Solution for Task #3</b></summary>\n",
    "\n",
    "```python\n",
    "def M(r, s, h1, h2):\n",
    "    \"\"\"Computes the L-infinity distance from coordinates to the center of a rectangle\n",
    "    \n",
    "    Args:\n",
    "        r (int): X coordinate.\n",
    "        s (int): Y coordinate.\n",
    "        h1 (int): Rectangle width.\n",
    "        h2 (int): Rectangle height.\n",
    "    \n",
    "    Returns:\n",
    "        int: Maximum absolute distance along either axis from point to rectangle center.\n",
    "    \"\"\"\n",
    "    n = h1 // 2\n",
    "    return max(abs(r - h1 // 2 - 1), abs(s - h2 // 2 - 1))\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f2a2e-4e79-424f-a470-e25d5f5f89bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def M(r, s, h1, h2):\n",
    "    \"\"\"Computes the L-infinity distance from coordinates to the center of a rectangle\n",
    "    \n",
    "    Args:\n",
    "        r (int): X coordinate.\n",
    "        s (int): Y coordinate.\n",
    "        h1 (int): Rectangle width.\n",
    "        h2 (int): Rectangle height.\n",
    "    \n",
    "    Returns:\n",
    "        int: Maximum absolute distance along either axis from point to rectangle center.\n",
    "    \"\"\"\n",
    "    \n",
    "    raise NotImplementedError(\"M hasn't been implemented.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c519910d-fd8d-42c3-a028-0310796873f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = xlab.tests.square.task3(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8774985-b038-4a8b-adb4-7924592b400d",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "Code the eta helper function for the $L_2$ distribution. This, using the $M$ helper function, creates a rectangle which has smoothed, radially decreasing pixel values. \n",
    "$$\n",
    "\\eta_{r,s}^{(h_1,h_2)} = \\sum_{k=0}^{M(r,s)} \\frac{1}{(n+1-k)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062b6d39-0c99-4165-8e5c-7492ff717d13",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <b>Hint for Task #4</b></summary>\n",
    "\n",
    "In our solution, we use a cache for faster computation, but this is not necessary.\n",
    "</details>\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>üîê <b>Solution for Task #4</b></summary>\n",
    "\n",
    "```python\n",
    "def eta(h1, h2):\n",
    "    \"\"\"Generates a weight matrix with harmonic series values based on distance from rectangle center\n",
    "    \n",
    "    Args:\n",
    "        h1 (int): Rectangle width.\n",
    "        h2 (int): Rectangle height.\n",
    "    \n",
    "    Returns:\n",
    "        [h1, h2]: Weight matrix where values increase with distance from center using harmonic progression.\n",
    "    \"\"\"\n",
    "    n = h1 // 2\n",
    "    m_matrix = torch.tensor([[M(i, j, h1, h2) for i in range(h2)] for j in range(h1)])\n",
    "    max_value = torch.max(m_matrix)\n",
    "    cache = []\n",
    "    t_sum = 0\n",
    "    for i in range(max_value):\n",
    "        if n+1-i != 0: \n",
    "            t_sum += 1 / (n+1-i)\n",
    "        cache.append(t_sum)\n",
    "    cache = torch.tensor(cache)\n",
    "    eta_matrix = cache[m_matrix - 1]\n",
    "    return eta_matrix\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48868343-5877-4b0f-b9d2-21c824cc3b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eta(h1, h2):\n",
    "    \"\"\"Generates a weight matrix with harmonic series values based on distance from rectangle center\n",
    "    \n",
    "    Args:\n",
    "        h1 (int): Rectangle width.\n",
    "        h2 (int): Rectangle height.\n",
    "    \n",
    "    Returns:\n",
    "        [h1, h2]: Weight matrix where values increase with distance from center using harmonic progression.\n",
    "    \"\"\"\n",
    "\n",
    "    raise NotImplementedError(\"eta hasn't been implemented.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b5610a-7234-46d8-8fe6-f4d5e3a43e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = xlab.tests.square.task4(eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932fd526-65f5-4229-b2c3-363c70a0fdf4",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "Now code the $L_2$ distribution using the above helper functions. This will use the eta function to create a square composed of two rectangles, one positive and one negative. This square is then randomly placed on the pixels of the image, and a scaled using a random scalar, to create a perturbation delta.\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "\\text{\\bf Algorithm: Sampling distribution } P \\text{ for } l_2\\text{-norm} \\\\\n",
    "\\hline\n",
    "\\text{\\bf Input: } \\text{maximal norm } \\epsilon, \\text{ window size } h, \\text{ image size } w, \\text{ number of color channels } c, \\\\\n",
    "\\quad \\text{current image } \\hat{x}, \\text{ original image } x \\\\\n",
    "\\text{\\bf Output: } \\text{New update } \\delta \\\\[0.5em]\n",
    "\\nu \\leftarrow \\hat{x} - x \\\\\n",
    "\\text{sample uniformly } r_1, s_1, r_2, s_2 \\in \\{0, \\dots, w - h\\} \\\\\n",
    "W_1 := r_1 + 1 : r_1 + h, s_1 + 1 : s_1 + h, W_2 := r_2 + 1 : r_2 + h, s_2 + 1 : s_2 + h \\\\\n",
    "k \\gets \\left\\lfloor \\frac{h}{2} \\right\\rfloor \\\\\n",
    "\\eta \\gets \\text{randomly choose } \\left( \\eta^{(h, \\ k)}, -\\eta^{(h, \\ h-k)} \\right) \\text{ or } \\left( \\eta^{(h, \\ k)}, -\\eta^{(h, \\ h-k)} \\right)^\\mathsf{T} \\\\\n",
    "\\eta^* \\leftarrow \\frac{\\eta}{\\lVert \\eta \\lVert_2} \\\\\n",
    "\\epsilon^2_{\\text{unused}} \\leftarrow \\epsilon^2 - \\lVert \\nu \\lVert_2^2 \\\\ \n",
    "\\text{\\bf for } i = 1, \\dots, c \\text{ \\bf do } \\\\\n",
    "\\quad \\rho \\leftarrow \\text{Uniform}(\\{-1, 1\\}) \\\\\n",
    "\\quad \\nu_{\\text{temp}} \\leftarrow \\rho\\eta^* + \\frac{\\nu_{W_1, i}}{\\lVert \\nu_{W_1, i} \\lVert_2} \\\\\n",
    "\\quad \\epsilon^i_{\\text{avail}} \\leftarrow \\sqrt{\\lVert \\nu_{W_1 \\cup W_2, i} \\lVert_2^2 + \\frac{\\epsilon^2_{\\text{unused}}}{c}} \\\\\n",
    "\\quad \\nu_{W_2, i} \\leftarrow 0, \\quad \\nu_{W_1, i} \\leftarrow \\left( \\frac{\\nu_{\\text{temp}}}{\\lVert \\nu_{\\text{temp}} \\lVert_2} \\right) \\epsilon^i_{\\text{avail}} \\\\\n",
    "\\text{\\bf end } \\\\\n",
    "\\delta \\leftarrow x + \\nu - \\hat{x} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf3cf75-ef2f-42ca-a88c-fecafdfb85d5",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <b>Hint for Task #5</b></summary>\n",
    "\n",
    "Cloning v at the beginning can avoid a logic error (delta updates are 0 every time)\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>üí° <b>Hint for Task #5</b></summary>\n",
    "\n",
    "Adding a very small number to calculation denominators can avoid nan or infinity errors.\n",
    "</details>\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>üîê <b>Solution for Task #5</b></summary>\n",
    "\n",
    "```python\n",
    "def l_2_dist(x_hat, x, epsilon = 1/1000, h = 10, w = 32, c = 3):\n",
    "    \"\"\"Generates L2-constrained perturbation update by redistributing energy between random square patches\n",
    "    \n",
    "    Args:\n",
    "        x_hat [1, c, w, w]: Current perturbed image tensor.\n",
    "        x [1, c, w, w]: Original clean image tensor.\n",
    "        epsilon (float): L2 perturbation budget constraint.\n",
    "        h (int): Height and width of square patches.\n",
    "        w (int): Image width and height.\n",
    "        c (int): Number of color channels.\n",
    "    \n",
    "    Returns:\n",
    "        [c, w, w]: Perturbation update tensor that redistributes energy while respecting L2 constraints.\n",
    "    \"\"\"\n",
    "    v = x_hat - x\n",
    "    v_new = v.clone()\n",
    "    \n",
    "    delta = torch.zeros(c,w,w)\n",
    "    r1, s1, r2, s2 = np.random.randint(w-h, size = (4))\n",
    "    v_sq = v ** 2\n",
    "    eps_unused = max(0, epsilon ** 2 - torch.sum(v_sq))\n",
    "    k = h // 2\n",
    "    \n",
    "    e1 = torch.hstack((eta(h, k), -1 * eta(h, h-k)))\n",
    "    e2 = torch.hstack((eta(h, k), -1 * eta(h, h-k))).T\n",
    "    e = random.choice([e1,e2])\n",
    "    eta_star = e / (torch.norm(e, p=2) + 1e-9)\n",
    "    \n",
    "    for i in range(c):\n",
    "        p = np.random.uniform(-1, 1)\n",
    "        W1 = v[0][i, r1:r1+h, s1:s1+h]\n",
    "        W2 = v[0][i, r2:r2+h, s2:s2+h]\n",
    "        \n",
    "        v_t = p * eta_star + W1 / (torch.norm(W1) + 1e-9)\n",
    "        e_avail = torch.sqrt(torch.sum(W1 ** 2) + torch.sum(W2 ** 2) + eps_unused / c)   \n",
    "        \n",
    "        v_new[0, i, r2:r2+h, s2:s2+h] = 0\n",
    "        v_new[0, i, r1:r1+h, s1:s1+h] = (v_t / (torch.norm(v_t) + 1e-9)) * e_avail\n",
    "\n",
    "    delta =  v_new - v\n",
    "    return delta\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b9a25f-3b1e-41ab-b004-ef6de64f8ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_2_dist(x_hat, x, epsilon = 1/1000, h = 10, w = 32, c = 3):\n",
    "    \"\"\"Generates L2-constrained perturbation update by redistributing energy between random square patches\n",
    "    \n",
    "    Args:\n",
    "        x_hat [1, c, w, w]: Current perturbed image tensor.\n",
    "        x [1, c, w, w]: Original clean image tensor.\n",
    "        epsilon (float): L2 perturbation budget constraint.\n",
    "        h (int): Height and width of square patches.\n",
    "        w (int): Image width and height.\n",
    "        c (int): Number of color channels.\n",
    "    \n",
    "    Returns:\n",
    "        [c, w, w]: Perturbation update tensor that redistributes energy while respecting L2 constraints.\n",
    "    \"\"\"\n",
    "    \n",
    "    raise NotImplementedError(\"l_2_dist hasn't been implemented.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a82e78-9ca5-4ded-a845-c962c49c79dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = xlab.tests.square.task5(l_2_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13529d99-f7bc-4f08-bda6-4419632f60fc",
   "metadata": {},
   "source": [
    "Now we implement the main loop for $L_2$ square attack. This is the same as the above $L_\\infty$, but uses the other distribution.\n",
    "The $L_2$ Attack is mathematically much slower than the $L_\\infty$ attack. Epsilon has been increased to ensure that the algorithm can run reasonably quickly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcf4039-71eb-4174-97f8-45bf2b0b6fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_2_square_attack(model, loss_fn, x, y, N, w=32, c=3, epsilon=100/1000, max_h = 10):\n",
    "    x_hat = x.clone()\n",
    "    loss = loss_fn(model(x), y)\n",
    "    i = 1\n",
    "    h = max_h\n",
    "    while i < N and prediction(model, x_hat)[0] == y:\n",
    "        if i % (N // max_h) == 0:\n",
    "            if h > 2:\n",
    "                h -= 1\n",
    "        delta = l_2_dist(x_hat, x, h=h, epsilon=epsilon, w=w, c=c)\n",
    "        x_new = x_hat + delta\n",
    "        x_new = torch.clamp(x_new, 0, 1)\n",
    "        loss_new = loss_fn(model(x_new), y)\n",
    "        if loss_new > loss:\n",
    "            loss = loss_new\n",
    "            x_hat = x_new \n",
    "        i += 1\n",
    "    return x_hat\n",
    "\n",
    "img = process_image(IMG_PATH)\n",
    "label = prediction(model, process_image(IMG_PATH))[0]\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "x_adv = l_2_square_attack(model, loss_fn, img, label, 5000)\n",
    "pred = prediction(model, x_adv)\n",
    "print(f\"{classes[pred[0]]} with probability {pred[1][0]:.4f}\")\n",
    "show_image(x_adv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
