{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22d34354-07dc-49f0-8aca-1f30fe67acc8",
   "metadata": {},
   "source": [
    "# Defensive Distillation\n",
    "\n",
    "The author's of [Distillation as a Defense to Adversarial\n",
    "Perturbations against Deep Neural Networks](https://arxiv.org/pdf/1511.04508#page=16&zoom=100,416,109) gives a discription of four key ideas behind distilling image classifiers as a defense against adversarial examples. \n",
    "\n",
    "1. Start with hard labels (they describe this a series of one-hot vectors, but that is not necessarily how they would be stored in memory).\n",
    "2. Train the initial model using a traditional procedure, but let the final layer have a softmax with a temperature greater than one.\n",
    "3. Create a new training set using the outputs of this initial model. That is, instead of starting with hard labels like the previous model, we start with soft labels outputed by the initial model.\n",
    "4. Train a new model from scratch using the same architecture but with the soft labels (and with the same temperature as before).\n",
    "\n",
    "\n",
    "In this notebook, you will implement the final 2 steps and evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c81c533-b7fc-4800-aa5b-e5d7c59eaf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Flatten, Linear, ReLU\n",
    "import xlab\n",
    "\n",
    "device = xlab.utils.get_best_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6c350e-c645-44c2-a4a6-e70a771aedeb",
   "metadata": {},
   "source": [
    "### Step 1 and 2: Train an image classifer on hard labels\n",
    "\n",
    "We have already completed this step for you. We trained a simple MLP on the MNIST dataset on for two epochs and achieved a 94.90% accuracy on the test set. Importantly, we use a softmax with temperature ($T=20$) as it is described on our [explainer page](https://xlabaisecurity.com/adversarial/defensive-distillation/).\n",
    "\n",
    "\n",
    "If interested you can see the output of our training run [here](https://github.com/zroe1/xlab-ai-security/blob/main/models/defensive_distillation/training_output.txt) and the complete code [here](https://github.com/zroe1/xlab-ai-security/tree/main/models/defensive_distillation). You will train your own version of this model for step 5 of this notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe2b029-8ffa-47f7-b37a-04a369127aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skeleton of the model we trained\n",
    "class FeedforwardMNIST(nn.Module):\n",
    "    \"\"\"Simple 4-layer MLP for MNIST classification\"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(FeedforwardMNIST, self).__init__()\n",
    "        \n",
    "        input_size = 28 * 28\n",
    "        self.fc1 = Linear(input_size, 256)\n",
    "        self.fc2 = Linear(256, 64)\n",
    "        self.fc3 = Linear(64, num_classes)\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.relu = ReLU()\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model_path = hf_hub_download(repo_id=\"uchicago-xlab-ai-security/base-mnist-model\", filename=\"mnist_mlp.pth\")\n",
    "model = torch.load(model_path, map_location=device, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3cd05df-0e2c-4535-aa79-42407a8f1b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedforwardMNIST(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d45200-0f5c-4cba-87a1-e4eeb18e9b9c",
   "metadata": {},
   "source": [
    "### Benchmark on PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "217f1e9c-cd59-49d8-aec4-e7d0605c2e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3, device='mps:0') tensor(7)\n",
      "tensor(2, device='mps:0') tensor(2)\n",
      "tensor(1, device='mps:0') tensor(1)\n",
      "tensor(0, device='mps:0') tensor(0)\n",
      "tensor(9, device='mps:0') tensor(4)\n",
      "tensor(1, device='mps:0') tensor(1)\n",
      "tensor(8, device='mps:0') tensor(4)\n",
      "tensor(8, device='mps:0') tensor(9)\n",
      "tensor(6, device='mps:0') tensor(5)\n",
      "tensor(9, device='mps:0') tensor(9)\n",
      "tensor(0, device='mps:0') tensor(0)\n",
      "tensor(8, device='mps:0') tensor(6)\n",
      "tensor(9, device='mps:0') tensor(9)\n",
      "tensor(0, device='mps:0') tensor(0)\n",
      "tensor(1, device='mps:0') tensor(1)\n",
      "tensor(3, device='mps:0') tensor(5)\n",
      "tensor(9, device='mps:0') tensor(9)\n",
      "tensor(7, device='mps:0') tensor(7)\n",
      "tensor(8, device='mps:0') tensor(3)\n",
      "tensor(9, device='mps:0') tensor(4)\n",
      "45.0% of attacks succeded\n"
     ]
    }
   ],
   "source": [
    "num_test_imgs = 20\n",
    "imgs, ys = xlab.utils.load_mnist_test_samples(num_test_imgs)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "num_success = 0\n",
    "\n",
    "for img, y in zip(imgs, ys):\n",
    "    adv_x = xlab.utils.PGD(model, loss_fn, img, y, epsilon=32/255, alpha=2/255, num_iters=100)\n",
    "    adv_y = torch.argmax(model(adv_x))\n",
    "\n",
    "    print(adv_y, y)\n",
    "    \n",
    "    if adv_y.item() != y:\n",
    "        num_success += 1\n",
    "\n",
    "print(f\"{(num_success / num_test_imgs) * 100:.4}% of attacks succeded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cae8a8-abdf-43f1-bf95-e32e538e16d2",
   "metadata": {},
   "source": [
    "## Step 3: Create new training set\n",
    "\n",
    "We will be training our distilled model on the labels of the pretrained model you have loaded above. \n",
    "\n",
    "\n",
    "The model you loaded however, gives logits, not a temperature-smoothed softmax, so to get the proper labels, you will first have to implement the function below which returns softmax with temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91d7b6b3-731a-4328-ad50-03227af74427",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = xlab.utils.get_mnist_train_loader(batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52423df3-dacf-4cc6-8d60-795b5f19b0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temp(inputs, T):\n",
    "    out = inputs / T\n",
    "    return F.softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f4e8ceb-d04f-4fdc-9267-76eefb158e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_labels(batch, T):\n",
    "    outs = model(batch)\n",
    "    outs = softmax_with_temp(outs, T)\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94cd53d1-8f70-4f4a-99d6-a2c39f79043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75b759a3-707a-4f66-836e-825875ad660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "soft_labels= []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_batch, _ in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        soft_labels_batch = get_batch_labels(x_batch, 20)\n",
    "    \n",
    "        imgs.append(x_batch.cpu())\n",
    "        soft_labels.append(soft_labels_batch.cpu())\n",
    "\n",
    "all_images = torch.cat(imgs, dim=0)\n",
    "all_soft_labels = torch.cat(soft_labels, dim=0)\n",
    "soft_label_dataset = TensorDataset(all_images, all_soft_labels)\n",
    "\n",
    "batch_size = 128\n",
    "soft_label_loader = DataLoader(\n",
    "    soft_label_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47cc578f-c835-4b89-b939-fd34371f7c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x176341f10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_label_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4424649d-17d9-4cab-b187-b36c45271c7d",
   "metadata": {},
   "source": [
    "The first step in contructing this new dataset is to implement `get_batch_labels` by calling the pretrained model with temperature T. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d16656-6349-4f65-a85b-8fafbcbf1ddb",
   "metadata": {},
   "source": [
    "## Step 4: Train distilled model\n",
    "\n",
    "The optimization problem from the original paper was formalized by the authors using the following equation:\n",
    "\n",
    "$$\n",
    "\\arg\\min_{\\theta_F} -\\frac{1}{|\\mathcal{X}|} \\sum_{X \\in \\mathcal{X}} \\sum_{i \\in 0..N} F_i(X) \\log F_i^d(X)\n",
    "$$\n",
    "\n",
    "The loss for a single example is simply cross entropy loss with soft labels:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(X) = -\\sum_{i \\in 0..N} F_i(X) \\log F_i^d(X)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30eea637-de24-49fa-a296-f110eb84bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skeleton of the model we trained\n",
    "distilled =  FeedforwardMNIST().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4569a3b2-cc57-41d7-803f-978d1898f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss_soft(soft_labels, probs):\n",
    "    assert soft_labels.shape == probs.shape\n",
    "\n",
    "    log_probs = torch.log(probs)\n",
    "    return torch.sum(-1 * log_probs *  soft_labels) / (batch_size * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1f78cf21-2de1-4f20-82d6-8406a249f54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, train_loader, T):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i, (img, soft_label) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            img, soft_label = img.to(device), soft_label.to(device)\n",
    "            logits = model(img)\n",
    "    \n",
    "            out = softmax_with_temp(logits, T)\n",
    "            batch_loss = cross_entropy_loss_soft(soft_label, out)\n",
    "    \n",
    "            if i % 50==0:\n",
    "                print(f\"Epoch #{epoch + 1}: batch loss = {batch_loss.item():.4f}\")\n",
    "    \n",
    "            batch_loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "09642d84-5b6c-4a3c-a62d-10ed48c41ef4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: batch loss = 0.0303\n",
      "Epoch #1: batch loss = 0.0229\n",
      "Epoch #1: batch loss = 0.0252\n",
      "Epoch #1: batch loss = 0.0243\n",
      "Epoch #1: batch loss = 0.0222\n",
      "Epoch #1: batch loss = 0.0237\n",
      "Epoch #1: batch loss = 0.0221\n",
      "Epoch #1: batch loss = 0.0213\n",
      "Epoch #1: batch loss = 0.0229\n",
      "Epoch #1: batch loss = 0.0199\n",
      "Epoch #2: batch loss = 0.0198\n",
      "Epoch #2: batch loss = 0.0212\n",
      "Epoch #2: batch loss = 0.0195\n",
      "Epoch #2: batch loss = 0.0210\n",
      "Epoch #2: batch loss = 0.0218\n",
      "Epoch #2: batch loss = 0.0214\n",
      "Epoch #2: batch loss = 0.0191\n",
      "Epoch #2: batch loss = 0.0242\n",
      "Epoch #2: batch loss = 0.0238\n",
      "Epoch #2: batch loss = 0.0241\n",
      "Epoch #3: batch loss = 0.0233\n",
      "Epoch #3: batch loss = 0.0256\n",
      "Epoch #3: batch loss = 0.0208\n",
      "Epoch #3: batch loss = 0.0211\n",
      "Epoch #3: batch loss = 0.0195\n",
      "Epoch #3: batch loss = 0.0204\n",
      "Epoch #3: batch loss = 0.0265\n",
      "Epoch #3: batch loss = 0.0247\n",
      "Epoch #3: batch loss = 0.0217\n",
      "Epoch #3: batch loss = 0.0212\n",
      "Epoch #4: batch loss = 0.0192\n",
      "Epoch #4: batch loss = 0.0251\n",
      "Epoch #4: batch loss = 0.0199\n",
      "Epoch #4: batch loss = 0.0222\n",
      "Epoch #4: batch loss = 0.0225\n",
      "Epoch #4: batch loss = 0.0188\n",
      "Epoch #4: batch loss = 0.0204\n",
      "Epoch #4: batch loss = 0.0179\n",
      "Epoch #4: batch loss = 0.0213\n",
      "Epoch #4: batch loss = 0.0154\n",
      "Epoch #5: batch loss = 0.0189\n",
      "Epoch #5: batch loss = 0.0188\n",
      "Epoch #5: batch loss = 0.0198\n",
      "Epoch #5: batch loss = 0.0227\n",
      "Epoch #5: batch loss = 0.0229\n",
      "Epoch #5: batch loss = 0.0157\n",
      "Epoch #5: batch loss = 0.0185\n",
      "Epoch #5: batch loss = 0.0184\n",
      "Epoch #5: batch loss = 0.0253\n",
      "Epoch #5: batch loss = 0.0189\n",
      "Epoch #6: batch loss = 0.0244\n",
      "Epoch #6: batch loss = 0.0207\n",
      "Epoch #6: batch loss = 0.0233\n",
      "Epoch #6: batch loss = 0.0225\n",
      "Epoch #6: batch loss = 0.0204\n",
      "Epoch #6: batch loss = 0.0181\n",
      "Epoch #6: batch loss = 0.0175\n",
      "Epoch #6: batch loss = 0.0188\n",
      "Epoch #6: batch loss = 0.0179\n",
      "Epoch #6: batch loss = 0.0157\n",
      "Epoch #7: batch loss = 0.0218\n",
      "Epoch #7: batch loss = 0.0219\n",
      "Epoch #7: batch loss = 0.0249\n",
      "Epoch #7: batch loss = 0.0197\n",
      "Epoch #7: batch loss = 0.0219\n",
      "Epoch #7: batch loss = 0.0180\n",
      "Epoch #7: batch loss = 0.0223\n",
      "Epoch #7: batch loss = 0.0205\n",
      "Epoch #7: batch loss = 0.0210\n",
      "Epoch #7: batch loss = 0.0221\n",
      "Epoch #8: batch loss = 0.0184\n",
      "Epoch #8: batch loss = 0.0186\n",
      "Epoch #8: batch loss = 0.0233\n",
      "Epoch #8: batch loss = 0.0240\n",
      "Epoch #8: batch loss = 0.0224\n",
      "Epoch #8: batch loss = 0.0268\n",
      "Epoch #8: batch loss = 0.0190\n",
      "Epoch #8: batch loss = 0.0199\n",
      "Epoch #8: batch loss = 0.0241\n",
      "Epoch #8: batch loss = 0.0219\n",
      "Epoch #9: batch loss = 0.0215\n",
      "Epoch #9: batch loss = 0.0216\n",
      "Epoch #9: batch loss = 0.0161\n",
      "Epoch #9: batch loss = 0.0193\n",
      "Epoch #9: batch loss = 0.0190\n",
      "Epoch #9: batch loss = 0.0167\n",
      "Epoch #9: batch loss = 0.0212\n",
      "Epoch #9: batch loss = 0.0213\n",
      "Epoch #9: batch loss = 0.0229\n",
      "Epoch #9: batch loss = 0.0219\n",
      "Epoch #10: batch loss = 0.0275\n",
      "Epoch #10: batch loss = 0.0235\n",
      "Epoch #10: batch loss = 0.0190\n",
      "Epoch #10: batch loss = 0.0188\n",
      "Epoch #10: batch loss = 0.0226\n",
      "Epoch #10: batch loss = 0.0160\n",
      "Epoch #10: batch loss = 0.0254\n",
      "Epoch #10: batch loss = 0.0188\n",
      "Epoch #10: batch loss = 0.0149\n",
      "Epoch #10: batch loss = 0.0222\n"
     ]
    }
   ],
   "source": [
    "train(distilled, 10, soft_label_loader, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "91a84edc-deed-4481-bc6a-a968a23c3247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9481"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlab.utils.evaluate_mnist_accuracy(distilled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f0ac639f-1c26-49ef-b822-295b63673538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7, device='mps:0') tensor(7)\n",
      "tensor(2, device='mps:0') tensor(2)\n",
      "tensor(1, device='mps:0') tensor(1)\n",
      "tensor(0, device='mps:0') tensor(0)\n",
      "tensor(4, device='mps:0') tensor(4)\n",
      "tensor(1, device='mps:0') tensor(1)\n",
      "tensor(4, device='mps:0') tensor(4)\n",
      "tensor(9, device='mps:0') tensor(9)\n",
      "tensor(6, device='mps:0') tensor(5)\n",
      "tensor(9, device='mps:0') tensor(9)\n",
      "tensor(0, device='mps:0') tensor(0)\n",
      "tensor(6, device='mps:0') tensor(6)\n",
      "tensor(9, device='mps:0') tensor(9)\n",
      "tensor(0, device='mps:0') tensor(0)\n",
      "tensor(1, device='mps:0') tensor(1)\n",
      "tensor(5, device='mps:0') tensor(5)\n",
      "tensor(9, device='mps:0') tensor(9)\n",
      "tensor(7, device='mps:0') tensor(7)\n",
      "tensor(5, device='mps:0') tensor(3)\n",
      "tensor(4, device='mps:0') tensor(4)\n",
      "10.0% of attacks succeded\n"
     ]
    }
   ],
   "source": [
    "num_test_imgs = 20\n",
    "imgs, ys = xlab.utils.load_mnist_test_samples(num_test_imgs)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "num_success = 0\n",
    "\n",
    "for img, y in zip(imgs, ys):\n",
    "    adv_x = xlab.utils.PGD(distilled, loss_fn, img, y, epsilon=32/255, alpha=2/255, num_iters=100)\n",
    "    adv_y = torch.argmax(distilled(adv_x))\n",
    "\n",
    "    print(adv_y, y)\n",
    "    \n",
    "    if adv_y.item() != y:\n",
    "        num_success += 1\n",
    "\n",
    "print(f\"{(num_success / num_test_imgs) * 100:.4}% of attacks succeded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8462726-a752-42e3-819c-57e9637169dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45be25f0-38a9-4203-ae56-43447cc5edf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f493f91b-9fd7-47bb-b6ef-a850f9d0ab58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
