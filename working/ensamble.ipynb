{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29538cf5-91d0-465b-b2b8-70dbfe1173fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import xlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = xlab.utils.get_best_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b634d506-6471-4390-978c-53fa4b3963a7",
   "metadata": {},
   "source": [
    "## Loading the MNIST Dataset\n",
    "\n",
    "Before we begin the attack, let's take a look at our data and the surrogate models we will be using for this notebook. First, you can see that the `xlab-security` packages provides you with `xlab.utils.load_mnist_test_samples` which you can use to load members of the MNIST handwritten digit test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a81fe26-05c6-487a-9314-36263572d1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([100, 1, 28, 28])\n",
      "Labels shape: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "mnist_images, mnist_labels = xlab.utils.load_mnist_test_samples(100)\n",
    "print(f\"Images shape: {mnist_images.shape}\")\n",
    "print(f\"Labels shape: {mnist_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f9b959-2cb3-4c62-b45c-cffa94191e07",
   "metadata": {},
   "source": [
    "We also provide you with `xlab.utils.show_grayscale_image` to plot MNIST images. You can change the `image_index` below to explore different images in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bc8a799-3d2d-4784-912d-5b62f7129d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 0\n",
    "xlab.utils.show_grayscale_image(mnist_images[image_index], title=f\"label={mnist_labels[image_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce44c9c-64a5-4467-91a8-bfdfc69ccdfe",
   "metadata": {},
   "source": [
    "## Loading White-Box Models\n",
    "\n",
    "Next let's load the models that we will use to generate our transferable adversarial examples. We will be using a diverse set of models:\n",
    "\n",
    "1. **A Resnet model**, similar to the MiniWideResnet model you used in previous sections.\n",
    "   * Test set accuracy: 97.61%\n",
    "3. **A CNN model**, which is a simple model that has three convolutional layers and three dense layers.\n",
    "   * Test set accuracy: 96.74%\n",
    "5. **A MLP model** which contains three standard fully connected layers.\n",
    "   * Test set accuracy: 94.27%\n",
    "\n",
    "Code for how we trained each of these models can be found [here](https://github.com/zroe1/xlab-ai-security/tree/main/models/MNIST_ensemble). To load the models on your computer, you can run the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ee07b06-e795-433e-959a-95b3e913a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from xlab.models import ConvolutionalMNIST, ResNetMNIST, BasicBlockMNIST, FeedforwardMNIST\n",
    "\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=\"uchicago-xlab-ai-security/mnist-ensemble\",\n",
    "    filename=\"mnist_wideresnet.pth\"\n",
    ")\n",
    "white_box1 = torch.load(model_path, map_location=device, weights_only=False)\n",
    "\n",
    "\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=\"uchicago-xlab-ai-security/mnist-ensemble\",\n",
    "    filename=\"mnist_simple_cnn.pth\"\n",
    ")\n",
    "white_box2 = torch.load(model_path, map_location=device, weights_only=False)\n",
    "\n",
    "\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=\"uchicago-xlab-ai-security/mnist-ensemble\",\n",
    "    filename=\"mnist_mlp.pth\"\n",
    ")\n",
    "white_box3 = torch.load(model_path, map_location=device, weights_only=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f7c1d-af78-46a1-944d-253ba8e1e4c7",
   "metadata": {},
   "source": [
    "## Loading Black-Box Models\n",
    "\n",
    "Now we can load our black box model which we will attempt to attack in this notebook. You will interact with this model through our python package and you wont be able to see anything about the model architecture. You will be able to only call `model.predict` to get model predictions for a set of images and `model.predict_proba` to get model probabilities for a set of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cd8d021-5440-452b-b54c-7d8d8b30f4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions=tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
      "        4, 0, 7, 4, 0, 1, 3, 1, 3, 0, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n",
      "        4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3, 7, 4, 6, 4, 3, 0, 7, 0,\n",
      "        2, 9, 1, 7, 3, 2, 9, 7, 7, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 9, 3, 1, 4,\n",
      "        1, 7, 6, 9])\n",
      "probabilities.shape=torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "import xlab\n",
    "from xlab.models import BlackBox\n",
    "\n",
    "# Load the black box model (downloads automatically)\n",
    "model = xlab.utils.load_black_box_model('mnist-black-box')\n",
    "\n",
    "# Make predictions (model details are hidden)\n",
    "predictions = model.predict(mnist_images)\n",
    "probabilities = model.predict_proba(mnist_images)\n",
    "\n",
    "print(f\"predictions={predictions}\")\n",
    "print(f\"probabilities.shape={probabilities.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3f91cd-cbe9-46a9-8bfe-770da6b79795",
   "metadata": {},
   "source": [
    "## Task #1: Ensemble Loss\n",
    "\n",
    "Given an array of $k$ alpha values and $k$ models you will give the weighted cross entropy loss by the following equation:\n",
    "\n",
    "$$\n",
    "\\mathrm{argmin}_\\delta \\  \\  D(\\delta) + \\sum_{i=1}^k \\alpha_i \\cdot \\ell_i(x + \\delta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1dd12db-3209-4aee-bd14-49a29e934584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_loss(alphas, models, img, target):\n",
    "    loss = torch.tensor(0.0).to(device)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for alpha, model in zip(alphas, models):\n",
    "        out = model(img)\n",
    "        model_loss = loss_fn(out, target)\n",
    "        loss += alpha * model_loss\n",
    "        # print(model_loss)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0976138a-d292-4f9b-9332-38d2112356c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mnist_images[0:1].to(device)\n",
    "alphas = [1/3, 1/3, 1/3]\n",
    "models = [white_box1, white_box2, white_box3]\n",
    "\n",
    "example_loss = ensemble_loss(alphas, models, img, torch.tensor([0]).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecc8fab-33cc-4b10-8332-8ed79436ed5f",
   "metadata": {},
   "source": [
    "## Task #2: Ensemble Attack\n",
    "\n",
    "Now you should be in a good position to complete the ensemble attack. This is exactly the same as PGD, but instead of using a typical loss like Cross Entropy, you will be using the ensemble loss you implemented in `Task #1`. Note that in the original paper, the authors implement something more similar to Carlini-Wagner with a hyperparameter $\\lambda$ which controls how much the distance metric is weighted in the final loss. For simplicity and compatibility with our tests you should use the update rule below:\n",
    "\n",
    "$$\n",
    "x'_i = x + \\mathrm{clip}_\\epsilon(\\alpha \\cdot \\mathrm{sign}(\\nabla \\mathrm{ensemble\\_loss}_{F,t}(x'_{i-1})))\n",
    "$$\n",
    "\n",
    "<b>Note:</b> You may use our solution to the clip function from the PGD notebook by calling `xlab.utils.clip`. You can also implement this functionality again within this notebook if you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "61ae2c59-eac0-4ab1-8078-03512f2c52a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.3986, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.8807, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.2954, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.6910, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.1181, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.5903, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.1305, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.0240, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.9716, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.9292, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8908, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8694, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8517, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8400, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8335, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8243, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8293, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8226, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8287, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8265, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8191, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8175, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8177, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8149, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8216, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8116, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8173, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8154, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8153, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8138, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8194, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8160, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8158, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8119, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8169, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8110, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8163, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8129, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8118, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8105, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8117, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8105, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8140, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8098, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8098, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8104, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8117, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8183, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8093, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8179, device='mps:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def ensemble_attack_PGD(alphas, models, img, target, epsilon=12/255, alpha=2/255, num_iters=50):\n",
    "    img_original = img.clone()\n",
    "    adv_img = xlab.utils.add_noise(img)\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        adv_img.requires_grad=True\n",
    "        loss = ensemble_loss(alphas, models, adv_img, target)\n",
    "        loss.backward()\n",
    "        print(loss)\n",
    "\n",
    "        grad = adv_img.grad.data\n",
    "        # print(grad)\n",
    "        adv_img.requires_grad_(False)\n",
    "        adv_img -= alpha * torch.sign(grad)\n",
    "        adv_img = xlab.utils.clip(adv_img, img_original, epsilon)\n",
    "\n",
    "    return adv_img\n",
    "\n",
    "img = mnist_images[2:3].to(device)\n",
    "adv_img = ensemble_attack_PGD(alphas, models, img, torch.tensor([2]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "27f15e03-33fb-4594-b878-b63ed5452a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.4023, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.8953, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.3039, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.7131, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.1407, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.6079, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.1211, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.0219, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.9559, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.9039, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8749, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8613, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8472, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8408, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8384, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8339, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8344, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8323, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8246, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8212, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8252, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8241, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8209, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8161, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8174, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8101, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8120, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8031, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8103, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8102, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8120, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8116, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8107, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8103, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8117, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8069, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8100, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8013, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8121, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8033, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8092, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8035, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8131, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8074, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8069, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8057, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8065, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8041, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8094, device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8048, device='mps:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mnist_images[2:3].to(device)\n",
    "adv_img = ensemble_attack_PGD(alphas, models, img, torch.tensor([2]).to(device))\n",
    "xlab.utils.show_grayscale_image(adv_img[0])\n",
    "predictions = model.predict(adv_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9ef6091d-6679-409c-abd0-03dc7b825dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(adv_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b3aaf86d-f404-4daf-8cad-8e4619b3513a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e898a4-749d-464c-b3ae-1a8e3297be51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63cd4464-83ac-4b32-8e5e-228349c2b930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e4175ad-6cfb-44db-beb7-5463a4c6b223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x166ab5590>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist_images[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24df4d28-6d04-44f7-a6cb-8a565c3f0aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4077bd7045d64ed1b9ef0e5bba41b73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mnist_simple_cnn.pth:   0%|          | 0.00/432k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from xlab.models import ConvolutionalMNIST\n",
    "\n",
    "# https://huggingface.co/uchicago-xlab-ai-security/tiny-wideresnet-cifar10\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=\"uchicago-xlab-ai-security/mnist-ensemble\",\n",
    "    filename=\"mnist_simple_cnn.pth\"\n",
    ")\n",
    "model = torch.load(model_path, map_location='cpu', weights_only=False)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90e0ccc2-ab6f-46dd-b1fe-47df1c6c0086",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model(mnist_images[\u001b[32m0\u001b[39m:\u001b[32m1\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model(mnist_images[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c96ea32b-a13f-4164-9ab1-610ae2f3309c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea358bf32ee64223b8728dad85031766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mnist_wideresnet.pth:   0%|          | 0.00/693k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from xlab.models import ResNetMNIST, BasicBlockMNIST\n",
    "\n",
    "# https://huggingface.co/uchicago-xlab-ai-security/tiny-wideresnet-cifar10\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=\"uchicago-xlab-ai-security/mnist-ensemble\",\n",
    "    filename=\"mnist_wideresnet.pth\"\n",
    ")\n",
    "model = torch.load(model_path, map_location='cpu', weights_only=False)\n",
    "_ = model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fac03f8-29d9-4790-ab52-6b4d2672fabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.7614, -0.1434, -2.2696, -2.6548, -0.9835, -6.6371, -9.8690,  6.9030,\n",
       "         -8.5592,  0.1233]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(mnist_images[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68c2d190-d7e6-43e1-a8a5-0478bf746c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8548fdb3f8134f3ab520de0492f2a735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mnist_mlp.pth:   0%|          | 0.00/166k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from xlab.models import FeedforwardMNIST\n",
    "\n",
    "# https://huggingface.co/uchicago-xlab-ai-security/tiny-wideresnet-cifar10\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=\"uchicago-xlab-ai-security/mnist-ensemble\",\n",
    "    filename=\"mnist_mlp.pth\"\n",
    ")\n",
    "model = torch.load(model_path, map_location='cpu', weights_only=False)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8964bb5-bde5-491f-b7ec-2629772cda7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.2652, -10.5678,   0.7676,   4.0928, -10.3465,   0.0514, -15.9896,\n",
       "           9.2350,  -2.0897,   2.2656]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(mnist_images[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7109710-ee39-4beb-b4d2-f91c9b1ce4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
